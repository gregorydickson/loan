```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘   â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â•‘
â•‘   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•   â•‘
â•‘   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—   â•‘
â•‘   â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â•šâ•â•â•â•â–ˆâ–ˆâ•‘   â•‘
â•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â•‘
â•‘   â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•â•    â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â•â•šâ•â•â•â•â•â•â•   â•‘
â•‘                                                                              â•‘
â•‘              ğŸ¤– AI-Powered Document Data Extraction System ğŸ¤–                â•‘
â•‘                                                                              â•‘
â•‘    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â•‘
â•‘    â”‚   ğŸ“„ PDF    â”‚                                      â”‚  ğŸ’¾ Data    â”‚      â•‘
â•‘    â”‚  ğŸ“ DOCX    â”‚  â”€â”€â”€â”€â”€â–¶  ğŸ” AI Extract  â”€â”€â”€â”€â”€â–¶       â”‚  âœ… Valid   â”‚      â•‘
â•‘    â”‚   ğŸ“· IMG    â”‚                                      â”‚  ğŸ“Š Ready   â”‚      â•‘
â•‘    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

# ğŸ“‹ Loan Document Data Extraction System

> ğŸ¤– **AI-Powered** | ğŸ“„ **Multi-Format** | ğŸ” **Traceable** | âš¡ **Production-Ready**

A production-grade system for extracting structured borrower data from loan documents (PDF, DOCX, images) using AI-powered document processing with **complete source traceability**.

<div align="center">

### ğŸš€ [**Try the Live Demo**](https://loan-frontend-prod-793446666872.us-central1.run.app/) ğŸš€

**Production deployment running on Google Cloud Run**

</div>

---

## ğŸŒŸ Highlights

| | |
|---|---|
| ğŸ§ª **865 Tests** | âœ… 93.5% Coverage |
| ğŸ“ **95,818 LOC** | ğŸš€ v2.0 Shipped 2026-01-25 |
| ğŸ”’ **mypy Strict** | ğŸ Python + ğŸ“˜ TypeScript |

---

## âœ¨ Features

- ğŸ“„ **Document Processing** â€” Parse PDF, DOCX, and scanned images with intelligent layout understanding
- ğŸ¤– **AI Extraction** â€” Extract borrower information using Google Gemini 3.0 with dynamic model selection
- âš¡ **Dual Pipeline Architecture** â€” Choose between Docling (fast page-level attribution) or LangExtract (precise character-level offsets)
- ğŸ”„ **Auto-Selection** â€” Intelligent routing or manual method selection via API
- ğŸ–¼ï¸ **LightOnOCR GPU** â€” High-quality OCR for scanned documents (scale-to-zero enabled)
- ğŸ” **Circuit Breaker** â€” Automatic fallback from LangExtract â†’ Docling on errors
- ğŸ” **Source Attribution** â€” Every extracted field traces back to source document and page (or character position)
- âœ… **Validation** â€” Automated format validation (SSN, phone, zip) with confidence scoring
- ğŸ–¥ï¸ **Web Dashboard** â€” React-based UI for document upload and borrower management

---

## ğŸ—ï¸ Architecture

The system follows a **document processing pipeline architecture**:

```mermaid
flowchart LR
    subgraph Upload["ğŸ“¤ Upload"]
        A[Document Upload]
    end

    subgraph OCR["ğŸ–¼ï¸ OCR Layer"]
        B{Scanned?}
        C[LightOnOCR GPU]
        D[Docling OCR]
    end

    subgraph Extract["ğŸ¤– Extraction"]
        E{Method}
        F[Docling + Gemini]
        G[LangExtract + Gemini]
    end

    subgraph Store["ğŸ’¾ Storage"]
        H[Validation]
        I[(PostgreSQL)]
    end

    subgraph Serve["ğŸŒ API"]
        J[FastAPI REST]
        K[Next.js Dashboard]
    end

    A --> B
    B -->|Yes| C
    B -->|No| E
    C --> E
    D -.->|Fallback| E
    E -->|docling| F
    E -->|langextract| G
    F --> H
    G --> H
    H --> I
    I --> J
    J --> K
```

ğŸ“š See [docs/SYSTEM_DESIGN.md](docs/SYSTEM_DESIGN.md) for detailed architecture documentation.

---

## ğŸ¯ Key Architectural Decisions

This section highlights the most important architectural and implementation decisions that shaped the system. Each decision was made to balance competing concerns like cost, accuracy, performance, and maintainability.

### ğŸ“„ Document Processing: Docling

**Decision:** Use Docling as the primary document processing engine for PDF, DOCX, and image parsing.

**Why:**
- Production-grade multi-format support with unified API
- Built-in OCR for scanned documents without external dependencies
- Table extraction with structure preservation (critical for income data in loan docs)
- Page-level provenance metadata enables source attribution
- Active IBM development with regular updates

**Tradeoff:** Heavy dependency (~500MB) causes slower Cloud Run cold starts, but the unified API and table support justify the cost.

ğŸ“– [ADR-001: Docling](docs/ARCHITECTURE_DECISIONS.md#adr-001-use-docling-for-document-processing)

### ğŸ¤– LLM: Gemini 3.0 with Dynamic Model Selection

**Decision:** Use Google Gemini 3.0 with automatic model selection between Flash (fast/cheap) and Pro (complex/accurate).

**Why:**
- State-of-the-art reasoning for complex multi-borrower document extraction
- Dynamic selection optimizes cost: Flash for standard docs, Pro for complex/poor-quality scans
- Native structured output support eliminates JSON parsing errors
- GCP integration simplifies auth and deployment

**Tradeoff:** API costs scale with volume, but accuracy gains and cost optimization through model selection justify the expense over local models.

**Critical config:** Temperature=1.0 (lower values cause response looping), no max_output_tokens limit (causes None response).

ğŸ“– [ADR-002: Gemini 3.0](docs/ARCHITECTURE_DECISIONS.md#adr-002-use-gemini-30-with-dynamic-model-selection)

### ğŸ¯ Dual Extraction Pipeline: Docling vs. LangExtract

**Decision:** Implement two extraction methods with different tradeoffs, selectable via API parameter.

**Pipelines:**
- **Docling** (default): Fast page-level attribution, lower cost, mature processing
- **LangExtract**: Precise character-level offsets (char_start/char_end), audit-ready grounding

**Why:**
- Audit-sensitive use cases require precise source grounding beyond page numbers
- Standard documents don't need character offsets, save cost with Docling
- User choice based on use case (fast vs. traceable)
- Few-shot examples in LangExtract allow domain customization without fine-tuning

**Tradeoff:** Dual pipeline adds complexity but provides flexibility for different accuracy/cost requirements.

ğŸ“– [ADR-018: LangExtract](docs/ARCHITECTURE_DECISIONS.md#adr-018-use-langextract-for-structured-extraction-with-character-offsets)

### ğŸ–¼ï¸ OCR: LightOnOCR with Scale-to-Zero GPU

**Decision:** Deploy LightOnOCR-2-1B on Cloud Run with L4 GPU, scale-to-zero for cost optimization.

**Why:**
- Superior OCR accuracy for poor-quality scans vs. Docling's built-in OCR
- Scale-to-zero (min_instances=0) eliminates $485/month baseline GPU cost
- Circuit breaker with Docling OCR fallback maintains availability
- Internal-only auth prevents unauthorized GPU usage

**Tradeoff:** 60-120s cold start latency when scaling from zero, but $0 baseline cost vs. $485/month always-on justifies the tradeoff for intermittent OCR workloads.

ğŸ“– [ADR-019: LightOnOCR](docs/ARCHITECTURE_DECISIONS.md#adr-019-use-lightonocr-with-scale-to-zero-gpu-service)

### ğŸ’¾ Database: PostgreSQL with Repository Pattern

**Decision:** Use PostgreSQL with async SQLAlchemy ORM and repository pattern with caller-controlled transactions.

**Why:**
- ACID transactions ensure data integrity across borrower, income, and source attribution records
- Foreign keys maintain referential integrity
- Efficient joins for complex source attribution queries
- Cloud SQL provides managed backups and point-in-time recovery
- Repository pattern enables atomic multi-repository operations

**Key patterns:**
- Repositories use `flush()` not `commit()` - caller controls transaction boundaries
- `expire_on_commit=False` for async compatibility
- `selectinload()` for eager loading prevents N+1 queries

**Tradeoff:** Schema migrations required for changes, but relational model fits borrower/income/source relationships better than document stores.

ğŸ“– [ADR-003: PostgreSQL](docs/ARCHITECTURE_DECISIONS.md#adr-003-use-postgresql-for-relational-storage) | [ADR-007: Repository Pattern](docs/ARCHITECTURE_DECISIONS.md#adr-007-repository-pattern-with-caller-controlled-transactions)

### â˜ï¸ Deployment: Cloud Run Serverless

**Decision:** Deploy on Cloud Run with serverless auto-scaling and direct VPC egress.

**Why:**
- Auto-scaling (0-10 instances) handles variable document upload workloads
- Pay-per-use pricing: scale to zero when idle eliminates baseline compute costs
- No cluster management overhead vs. GKE
- Direct VPC egress for Cloud SQL private IP (no VPC Connector cost)

**Configuration:**
- Backend: 1Gi memory for Docling processing
- Frontend: 512Mi memory
- Startup probe on /health with 10s initial delay

**Tradeoff:** Cold start latency (especially with Docling model loading), but zero-idle cost and no ops overhead justify the tradeoff.

ğŸ“– [ADR-004: Cloud Run](docs/ARCHITECTURE_DECISIONS.md#adr-004-deploy-on-cloud-run-with-serverless-architecture)

### ğŸ”§ CI/CD: CloudBuild vs. Terraform

**Decision:** Migrate from Terraform to CloudBuild for application deployments (infrastructure provisioned via one-time gcloud scripts).

**Why:**
- Cloud Run deployments are frequent (every code push), infrastructure changes are rare
- CloudBuild provides simpler YAML configs vs. Terraform HCL
- Native GitHub triggers for automatic builds on push to main
- No Terraform state management complexity for simple service deploys
- Built-in revision tracking and rollback via Cloud Run console

**Tradeoff:** Lost declarative infrastructure-as-code for Cloud Run services, but faster iteration and simpler CI/CD justify the trade.

ğŸ“– [ADR-020: CloudBuild](docs/ARCHITECTURE_DECISIONS.md#adr-020-migrate-from-terraform-to-cloudbuild-for-deployments)

### ğŸ”’ Security: Private VPC + Secret Manager

**Decision:** Cloud SQL with private IP only (no public internet access) and credentials stored in Secret Manager.

**Why:**
- Database contains sensitive PII (SSN, income history) - no internet exposure
- VPC peering isolates database from public internet
- Secret Manager provides audit trail for credential access
- Secret rotation without redeployment via secret versions

**Tradeoff:** Cannot connect directly from local dev (requires Cloud SQL Auth Proxy), but security posture for PII data justifies the complexity.

ğŸ“– [ADR-013: Private VPC](docs/ARCHITECTURE_DECISIONS.md#adr-013-private-vpc-for-cloud-sql-no-public-ip) | [ADR-014: Secret Manager](docs/ARCHITECTURE_DECISIONS.md#adr-014-secret-manager-for-credentials)

### ğŸ¨ Frontend: Next.js 14 App Router

**Decision:** Use Next.js 14+ with App Router and shadcn/ui components.

**Why:**
- Server components reduce client bundle size
- App router provides file-based routing and better code organization
- shadcn/ui provides high-quality, accessible components (new-york style)
- Standalone build mode produces optimized Docker images (~100MB vs ~500MB)

**Tradeoff:** App router has learning curve vs. pages router, but server components and modern patterns justify the migration.

ğŸ“– [ADR-005: Next.js 14](docs/ARCHITECTURE_DECISIONS.md#adr-005-use-nextjs-14-app-router-for-frontend)

### ğŸ“Š Data Quality: Deduplication + Anomaly Detection

**Decision:** Multi-tier deduplication (SSN > Account > Fuzzy Name) and income anomaly flagging (50% drop, 300% spike).

**Why:**
- Same borrower appears across multiple documents/chunks
- Unique identifiers (SSN, account) prevent false merges
- Fuzzy name matching (90%+) handles variations ("John Smith" vs. "J. Smith")
- Income anomaly detection catches data errors and potential fraud
- Flags for review, doesn't auto-reject (human in the loop)

**Tradeoff:** May miss sophisticated manipulation, but balance between automation and accuracy is appropriate for financial documents.

ğŸ“– [ADR-009: Deduplication](docs/ARCHITECTURE_DECISIONS.md#adr-009-deduplication-priority-order-ssn--account--fuzzy-name) | [ADR-017: Anomaly Thresholds](docs/ARCHITECTURE_DECISIONS.md#adr-017-income-anomaly-thresholds-50-drop-300-spike)

---

**ğŸ“š Complete Decision Records:** See [docs/ARCHITECTURE_DECISIONS.md](docs/ARCHITECTURE_DECISIONS.md) for all 20 ADRs with full context, alternatives considered, and consequences.

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | Purpose | Emoji |
|-----------|------------|---------|-------|
| ğŸ Backend | FastAPI | Async REST API with OpenAPI docs | âš¡ |
| ğŸ–¥ï¸ Frontend | Next.js 14 | React dashboard with App Router | âš›ï¸ |
| ğŸ“„ Doc Processing | Docling | PDF/DOCX/Image parsing with OCR | ğŸ“‹ |
| ğŸ¯ Extraction | LangExtract | Character-level attribution extraction | ğŸ” |
| ğŸ¤– LLM | Google Gemini 3.0 | Flash (standard) / Pro (complex) | ğŸ’¡ |
| ğŸ–¼ï¸ OCR | LightOnOCR | GPU-accelerated scanned doc OCR | ğŸš€ |
| ğŸ’¾ Database | PostgreSQL 16 | Relational storage with async driver | ğŸ—„ï¸ |
| â˜ï¸ Storage | Cloud Storage | Document file storage | ğŸ“¦ |
| ğŸš€ Deployment | Cloud Run | Serverless containers (incl. GPU) | ğŸ³ |
| ğŸ”§ CI/CD | CloudBuild | GitHub-triggered deployments | ğŸ”„ |
| ğŸ—ï¸ Infrastructure | gcloud CLI | Infrastructure provisioning scripts | ğŸ“ |

---

## ğŸ“Š Project Metrics

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ“ˆ v2.0 Statistics                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ§ª Tests:        865 passing                               â”‚
â”‚  ğŸ“Š Coverage:     93.5%                                     â”‚
â”‚  ğŸ“ Lines:        95,818 LOC                                â”‚
â”‚  âœ… Requirements: 294/294 (v1.0: 222, v2.0: 72)             â”‚
â”‚  ğŸ“¦ Phases:       18 complete                               â”‚
â”‚  ğŸ“‹ Plans:        64 executed                               â”‚
â”‚  ğŸ”’ Type Safety:  mypy strict (0 errors)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Prerequisites

Before you begin, ensure you have the following installed:

| Requirement | Version | Check Command |
|-------------|---------|---------------|
| ğŸ Python | 3.10+ | `python --version` |
| ğŸ“¦ Node.js | 20+ | `node --version` |
| ğŸ³ Docker | Latest | `docker --version` |
| â˜ï¸ gcloud CLI | Latest | `gcloud --version` |
| ğŸ”‘ Gemini API Key | â€” | [Get from AI Studio](https://aistudio.google.com/) |

---

## ğŸš€ Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <repository-url>
cd loan
```

### 2ï¸âƒ£ Backend Setup

```bash
cd backend

# ğŸ Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# ğŸ“¦ Install dependencies (including dev tools)
pip install -e ".[dev]"
```

### 3ï¸âƒ£ Frontend Setup

```bash
cd frontend

# ğŸ“¦ Install dependencies
npm install
```

### 4ï¸âƒ£ Environment Configuration

Create `.env` files for local development:

**ğŸ“ backend/.env:**
```bash
DATABASE_URL=postgresql+asyncpg://postgres:postgres@localhost:5432/loan_extraction
GCS_BUCKET_NAME=  # Optional for local dev (mock GCS client used when not set)
GEMINI_API_KEY=your-api-key-here
GOOGLE_API_KEY=your-api-key-here  # For LangExtract (same key)
```

**ğŸ“ frontend/.env.local:**
```bash
NEXT_PUBLIC_API_URL=http://localhost:8000
```

---

## ğŸƒ Running Locally

### ğŸ³ Start Infrastructure

```bash
# Start PostgreSQL and Redis
docker-compose up -d
```

This starts:
- ğŸ—„ï¸ PostgreSQL 16 on port 5432 (database: `loan_extraction`, user: `postgres`, password: `postgres`)
- ğŸ“® Redis 7 on port 6379

### ğŸ“Š Run Database Migrations

```bash
cd backend
source venv/bin/activate
alembic upgrade head
```

### ğŸ–¥ï¸ Start Backend Server

```bash
cd backend
source venv/bin/activate
uvicorn src.main:app --reload --host 0.0.0.0 --port 8000
```

ğŸŒ The API will be available at:
- ğŸ“¡ API: http://localhost:8000
- ğŸ“š Docs: http://localhost:8000/docs
- â¤ï¸ Health: http://localhost:8000/health

### ğŸ’» Start Frontend Development Server

```bash
cd frontend
npm run dev
```

ğŸ–¥ï¸ The dashboard will be available at http://localhost:3000

---

## ğŸ§ª Development

### ğŸ”¬ Running Tests

```bash
cd backend
source venv/bin/activate

# ğŸ§ª Run all tests with coverage
pytest

# ğŸ“ Run only unit tests
pytest tests/unit

# ğŸ“„ Run specific test file
pytest tests/extraction/test_llm_client.py

# ğŸ“Š Run with verbose output and HTML coverage report
pytest -v --cov-report=html
```

### âœ… Code Quality

```bash
cd backend
source venv/bin/activate

# ğŸ”’ Type checking (strict mode)
mypy src/

# ğŸ” Linting
ruff check src/

# âœ¨ Format code
ruff format src/
```

### ğŸ’» Frontend Development

```bash
cd frontend

# ğŸ”’ Type checking
npx tsc --noEmit

# ğŸ” Linting
npm run lint

# ğŸ“¦ Build for production
npm run build
```

---

## ğŸ“ Project Structure

```
loan/
â”œâ”€â”€ ğŸ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/           # ğŸŒ FastAPI routes and endpoints
â”‚   â”‚   â”œâ”€â”€ extraction/    # ğŸ¤– LLM extraction and validation logic
â”‚   â”‚   â”œâ”€â”€ ingestion/     # ğŸ“„ Document processing with Docling
â”‚   â”‚   â”œâ”€â”€ ocr/           # ğŸ–¼ï¸ LightOnOCR client and router
â”‚   â”‚   â”œâ”€â”€ models/        # ğŸ“‹ Pydantic schemas and SQLAlchemy models
â”‚   â”‚   â””â”€â”€ storage/       # ğŸ’¾ Database repositories and GCS client
â”‚   â”œâ”€â”€ tests/             # ğŸ§ª pytest unit and integration tests
â”‚   â””â”€â”€ alembic/           # ğŸ“Š Database migrations
â”œâ”€â”€ ğŸ’» frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/           # ğŸ“± Next.js pages and routes
â”‚   â”‚   â”œâ”€â”€ components/    # ğŸ¨ React components (shadcn/ui)
â”‚   â”‚   â””â”€â”€ lib/           # ğŸ”§ API client and utilities
â”‚   â””â”€â”€ public/            # ğŸ–¼ï¸ Static assets
â”œâ”€â”€ ğŸ—ï¸ infrastructure/
â”‚   â”œâ”€â”€ cloudbuild/        # ğŸ”§ CloudBuild YAML configs
â”‚   â””â”€â”€ scripts/           # ğŸ“ Deployment automation scripts
â”œâ”€â”€ ğŸ“š docs/               # ğŸ“– Documentation
â”œâ”€â”€ ğŸ³ docker-compose.yml  # Local development infrastructure
â””â”€â”€ ğŸ“‹ README.md           # This file
```

---

## â˜ï¸ Deployment

### ğŸ“‹ Prerequisites

1. â˜ï¸ Google Cloud project with billing enabled
2. ğŸ”§ gcloud CLI installed and authenticated (`gcloud auth login`)
3. ğŸ³ Docker installed for building images

### ğŸ—ï¸ Initialize GCP Resources

```bash
cd infrastructure/scripts
chmod +x setup-gcp.sh provision-infra.sh

# ğŸš€ Initialize GCP project (enables APIs, creates resources)
./setup-gcp.sh YOUR_PROJECT_ID us-central1

# ğŸ—ï¸ Provision infrastructure
./provision-infra.sh YOUR_PROJECT_ID us-central1
```

### ğŸ”§ Set Up CloudBuild Triggers

```bash
cd infrastructure/scripts

# ğŸ”— Connect GitHub and create triggers
./setup-github-triggers.sh YOUR_PROJECT_ID us-central1 your-github-repo
```

### ğŸš€ Deploy Services

Services deploy automatically on push to main branch via CloudBuild triggers:

- ğŸ **Backend**: `backend-cloudbuild.yaml`
- ğŸ’» **Frontend**: `frontend-cloudbuild.yaml`
- ğŸ–¼ï¸ **GPU Service**: `gpu-cloudbuild.yaml`

ğŸ“š See [docs/cloudbuild-deployment-guide.md](docs/cloudbuild-deployment-guide.md) for detailed deployment instructions.

### ğŸ”‘ Environment Variables (Production)

Managed automatically via Secret Manager:
- ğŸ”— `DATABASE_URL`: Cloud SQL connection string (private IP)
- ğŸ”‘ `GEMINI_API_KEY`: Gemini API key
- ğŸ“¦ `GCS_BUCKET_NAME`: Document storage bucket name

---

## ğŸ“¡ API Usage

### ğŸ“¤ Upload a Document

```bash
# ğŸ“„ Default (Docling extraction)
curl -X POST http://localhost:8000/api/documents \
  -F "file=@/path/to/document.pdf"

# ğŸ¯ With LangExtract (character-level attribution)
curl -X POST "http://localhost:8000/api/documents?method=langextract" \
  -F "file=@/path/to/document.pdf"

# ğŸ–¼ï¸ Force OCR for scanned documents
curl -X POST "http://localhost:8000/api/documents?method=docling&ocr=force" \
  -F "file=@/path/to/scanned.pdf"
```

**ğŸ“‹ Response:**
```json
{
  "id": "550e8400-e29b-41d4-a716-446655440000",
  "filename": "document.pdf",
  "status": "completed",
  "page_count": 5,
  "extraction_method": "langextract",
  "ocr_processed": false
}
```

### ğŸ” Extraction Method Options

| Parameter | Options | Description |
|-----------|---------|-------------|
| `method` | `docling` (default), `langextract`, `auto` | ğŸ¤– Extraction pipeline to use |
| `ocr` | `auto` (default), `force`, `skip` | ğŸ–¼ï¸ OCR behavior for scanned docs |

ğŸ“š See [docs/api/extraction-method-guide.md](docs/api/extraction-method-guide.md) for detailed API guide.

### ğŸ“Š Get Document Status

```bash
curl http://localhost:8000/api/documents/{document_id}/status
```

**ğŸ“‹ Response:**
```json
{
  "status": "completed",
  "page_count": 5,
  "extraction_method": "docling",
  "ocr_processed": true,
  "error_message": null
}
```

### ğŸ“‹ List Documents

```bash
curl "http://localhost:8000/api/documents?page=1&page_size=10"
```

### ğŸ‘¥ List Borrowers

```bash
curl "http://localhost:8000/api/borrowers?page=1&page_size=10"
```

**ğŸ“‹ Response:**
```json
{
  "borrowers": [
    {
      "id": "uuid",
      "name": "John Smith",
      "ssn_last_four": "1234",
      "income_count": 3
    }
  ],
  "total": 1,
  "page": 1,
  "page_size": 10
}
```

### ğŸ‘¤ Get Borrower Details

```bash
curl http://localhost:8000/api/borrowers/{borrower_id}
```

**ğŸ“‹ Response includes:**
- ğŸ‘¤ Borrower information (name, SSN, address, phone)
- ğŸ’° Income records with amounts and periods
- ğŸ”¢ Account numbers
- ğŸ“„ Source references (document ID, page number, text snippet)
- ğŸ” Character offsets (when using LangExtract)

### ğŸ” Search Borrowers

```bash
# ğŸ‘¤ Search by name
curl "http://localhost:8000/api/borrowers/search?name=John"

# ğŸ”¢ Search by account number
curl "http://localhost:8000/api/borrowers/search?account_number=12345"
```

### â¤ï¸ Health Check

```bash
curl http://localhost:8000/health
```

**ğŸ“‹ Response:**
```json
{
  "status": "healthy"
}
```

---

## ğŸ“š Documentation

### ğŸ—ï¸ Architecture & Design

| Document | Description |
|----------|-------------|
| ğŸ“ [System Design](docs/SYSTEM_DESIGN.md) | Architecture, pipeline, scaling analysis |
| ğŸ“ [Architecture Decisions](docs/ARCHITECTURE_DECISIONS.md) | ADRs for technology choices |

### ğŸ“– Guides

| Guide | Description |
|-------|-------------|
| ğŸ¤– [Extraction Method Guide](docs/api/extraction-method-guide.md) | API parameters and method selection |
| ğŸ“ [Few-Shot Examples](docs/guides/few-shot-examples.md) | Creating extraction schema examples |
| ğŸ’° [GPU Service Cost](docs/guides/gpu-service-cost.md) | Cost management strategies |
| ğŸ–¼ï¸ [LightOnOCR Deployment](docs/guides/lightonocr-deployment.md) | GPU service deployment |
| ğŸš€ [CloudBuild Deployment](docs/cloudbuild-deployment-guide.md) | CI/CD deployment guide |

### ğŸ”„ Migration & Operations

| Document | Description |
|----------|-------------|
| ğŸ”„ [Terraform Migration](docs/migration/terraform-migration.md) | Terraform to CloudBuild migration |
| ğŸ“‹ [Terraform Inventory](docs/terraform-to-gcloud-inventory.md) | gcloud CLI equivalents |

---

## ğŸ†• v2.0 Release Notes (2026-01-25)

### ğŸ¯ Dual Extraction Pipelines

**Docling Pipeline** (default)
- âš¡ Fast page-level attribution
- ğŸ“„ Built-in OCR for scanned documents
- ğŸ”§ Mature, battle-tested processing

**LangExtract Pipeline** (new)
- ğŸ¯ Character-level source attribution (char_start/char_end)
- ğŸ“ Few-shot example-based extraction schema
- ğŸ” Precise text grounding for verification

### ğŸ–¼ï¸ LightOnOCR GPU Service

- ğŸš€ High-quality OCR powered by LightOn VLM
- ğŸ’° Scale-to-zero ($0 baseline vs $485/month always-on)
- ğŸ” Circuit breaker fallback to Docling OCR
- âš¡ L4 GPU for fast processing

### ğŸ”§ CloudBuild CI/CD

- ğŸ”— GitHub-triggered deployments
- ğŸ“¦ Separate configs for backend, frontend, GPU
- ğŸ”„ Replaces Terraform for application deployments
- ğŸ—ï¸ Infrastructure via gcloud CLI scripts

### ğŸ“Š Quality Improvements

- ğŸ§ª 865 tests (up from 283 in v1.0, +375 tests)
- ğŸ“Š 93.5% coverage (threshold: 80%)
- ğŸ”’ mypy strict compliance (0 errors)

---

## ğŸ“œ License

MIT

---

<div align="center">

```
 _____ _                 _           __             _   _     _
|_   _| |__   __ _ _ __ | | _____   / _| ___  _ __| | | |___(_)_ __   __ _
  | | | '_ \ / _` | '_ \| |/ / __|  | |_ / _ \| '__| | | / __| | '_ \ / _` |
  | | | | | | (_| | | | |   <\__ \  |  _| (_) | |  | |_| \__ \ | | | | (_| |
  |_| |_| |_|\__,_|_| |_|_|\_\___/  |_|  \___/|_|   \___/|___/_|_| |_|\__, |
                                                                        |___/
```

**Built with** ğŸ’» **FastAPI** + âš›ï¸ **Next.js** + ğŸ¤– **Gemini** + â˜ï¸ **GCP**

ğŸŒŸ Star this repo if you found it helpful!

</div>
