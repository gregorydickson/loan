---
phase: 07-documentation-testing
plan: 04
type: execute
wave: 2
depends_on: []
files_modified:
  - backend/tests/unit/test_docling_processor.py
  - backend/tests/unit/test_document_service.py
  - backend/tests/unit/test_gcs_client.py
  - backend/tests/unit/test_models.py
  - backend/tests/unit/test_borrower_repository.py
  - backend/tests/unit/test_borrower_routes.py
  - backend/tests/integration/test_documents_api.py
  - backend/tests/integration/test_sample_documents.py
  - backend/tests/extraction/test_extractor.py
  - backend/tests/extraction/test_llm_client.py
  - backend/pyproject.toml
  - frontend/e2e/smoke.spec.ts
  - frontend/package.json
autonomous: true

must_haves:
  truths:
    - "pytest coverage report shows >80% backend coverage"
    - "All test files cover error paths and edge cases"
    - "Integration tests validate upload-to-query flow"
    - "pytest-xdist installed for parallel test execution"
    - "Sample loan documents integration test validates real corpus extraction"
    - "Frontend smoke tests cover dashboard load and document upload"
  artifacts:
    - path: "backend/tests/unit/test_docling_processor.py"
      provides: "Comprehensive Docling processor tests"
      contains: ["test_process_pdf", "test_process_docx", "test_process_image"]
    - path: "backend/tests/integration/test_e2e_flow.py"
      provides: "End-to-end flow test"
      contains: ["test_upload_to_extraction_flow"]
    - path: "backend/tests/integration/test_sample_documents.py"
      provides: "Sample loan documents integration test"
      contains: ["test_sample_loan_document_extraction"]
    - path: "frontend/e2e/smoke.spec.ts"
      provides: "Frontend smoke tests"
      contains: ["test.describe", "dashboard", "upload"]
  key_links:
    - from: "backend/tests/"
      to: "backend/src/"
      via: "Tests cover source modules"
      pattern: "from src\\."
---

<objective>
Expand test coverage to achieve >80% backend coverage by adding targeted tests for uncovered modules and error paths.

Purpose: Ensure production-quality test suite that validates all critical functionality, error handling, and edge cases.

Output: Extended test files with comprehensive coverage, pytest-xdist for parallel execution, and validated 80%+ coverage.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/07-documentation-testing/07-CONTEXT.md
@.planning/phases/07-documentation-testing/07-RESEARCH.md

# Existing test infrastructure
@backend/tests/conftest.py
@backend/tests/integration/conftest.py
@backend/pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Establish Coverage Baseline and Add pytest-xdist</name>
  <files>backend/pyproject.toml</files>
  <action>
First, establish the current coverage baseline by running existing tests. Then add pytest-xdist for parallel execution.

**Step 1: Run coverage baseline**
```bash
cd backend
pytest --cov=src --cov-report=term-missing --cov-report=html
```
Note which modules have low coverage for targeting.

**Step 2: Update pyproject.toml to add pytest-xdist:**

Add to `[project.optional-dependencies]` dev section:
```toml
"pytest-xdist>=3.0.0",
```

**Step 3: Add coverage configuration:**

Add to pyproject.toml:
```toml
[tool.coverage.run]
source = ["src"]
branch = true
omit = ["*/__init__.py"]

[tool.coverage.report]
exclude_also = [
    "def __repr__",
    "if TYPE_CHECKING:",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
    "@abstractmethod",
]
fail_under = 80
show_missing = true
```

**Step 4: Install updated dependencies:**
```bash
pip install -e ".[dev]"
```
  </action>
  <verify>
```bash
cd backend
pip show pytest-xdist  # Should show installed
grep "fail_under = 80" pyproject.toml  # Coverage threshold set
# Verify baseline coverage report was generated
test -f htmlcov/index.html && echo "Coverage report generated"
pytest --cov=src --cov-report=term-missing | head -50  # Show current coverage baseline
```
  </verify>
  <done>
Coverage baseline established and documented (initial % noted), pytest-xdist added, coverage fail threshold configured at 80%
  </done>
</task>

<task type="auto">
  <name>Task 2: Expand Unit Tests for Core Modules</name>
  <files>
    backend/tests/unit/test_docling_processor.py
    backend/tests/unit/test_document_service.py
    backend/tests/unit/test_gcs_client.py
    backend/tests/unit/test_models.py
  </files>
  <action>
Expand existing unit tests to cover error paths and edge cases.

**test_docling_processor.py - Add tests for:**
- PDF processing with various page counts (TEST-01)
- DOCX processing (TEST-01)
- Image processing with OCR (TEST-01)
- Error handling for corrupted files
- Empty document handling
- Large document handling (memory considerations)

Pattern:
```python
@pytest.mark.asyncio
async def test_process_pdf_extracts_text():
    """Test PDF processing extracts text with page boundaries."""
    ...

@pytest.mark.asyncio
async def test_process_pdf_handles_corrupted_file():
    """Test graceful handling of corrupted PDF."""
    ...

@pytest.mark.asyncio
async def test_process_docx_preserves_layout():
    """Test DOCX processing preserves layout information."""
    ...

@pytest.mark.asyncio
async def test_process_image_with_ocr():
    """Test image processing uses OCR for text extraction."""
    ...
```

**test_document_service.py - Add tests for (TEST-02):**
- Upload with mock GCS and Docling
- Duplicate detection (same file hash)
- Error handling for GCS failures
- Error handling for Docling failures
- Status transitions (PENDING -> PROCESSING -> COMPLETED/FAILED)

**test_gcs_client.py - Add tests for (TEST-03):**
- Upload returns gs:// URI
- Download retrieves file content
- Exists check returns correct boolean
- Signed URL generation
- Error handling for missing bucket

**test_models.py - Add tests for (TEST-10):**
- Document model relationships
- Borrower model relationships
- IncomeRecord model relationships
- SourceReference model relationships
- All models serialize to JSON correctly

Use MagicMock(spec=Class) pattern for type-safe mocks as documented in research.
  </action>
  <verify>
```bash
cd backend
pytest tests/unit/test_docling_processor.py tests/unit/test_document_service.py tests/unit/test_gcs_client.py tests/unit/test_models.py -v
```
All new tests pass.
  </verify>
  <done>
Unit tests expanded for Docling processor, document service, GCS client, and database models with error path coverage
  </done>
</task>

<task type="auto">
  <name>Task 3: Expand Extraction and API Tests, Add E2E Test</name>
  <files>
    backend/tests/extraction/test_extractor.py
    backend/tests/extraction/test_llm_client.py
    backend/tests/unit/test_borrower_repository.py
    backend/tests/unit/test_borrower_routes.py
    backend/tests/integration/test_e2e_flow.py
  </files>
  <action>
Add comprehensive tests for extraction logic and create E2E integration test.

**test_extractor.py - Add tests for (TEST-07):**
- Chunking large documents correctly
- Deduplication by SSN
- Deduplication by account number
- Deduplication by fuzzy name match
- Aggregating results from multiple chunks
- Source attribution tracking

**test_llm_client.py - Add tests for (TEST-05):**
- Successful extraction with mock response
- Retry on rate limit (429)
- Retry on server error (5xx)
- Timeout handling
- None response handling (max_output_tokens exceeded)
- Token usage tracking

Pattern for mock Gemini response:
```python
def create_mock_response(text: str, prompt_tokens: int = 100, candidate_tokens: int = 50):
    """Create mock Gemini response with usage metadata."""
    mock = MagicMock()
    mock.text = text
    mock.usage_metadata = MagicMock()
    mock.usage_metadata.prompt_token_count = prompt_tokens
    mock.usage_metadata.candidates_token_count = candidate_tokens
    return mock
```

**test_borrower_repository.py - Add tests for (TEST-11):**
- Create borrower with related entities
- Get borrower by ID with relationships loaded
- Search by name
- Search by account number
- Pagination
- Empty results handling

**test_borrower_routes.py - Add tests for (TEST-12, TEST-13):**
- GET /api/borrowers list endpoint
- GET /api/borrowers/{id} detail endpoint
- GET /api/borrowers/search with name query
- GET /api/borrowers/search with account query
- 404 for non-existent borrower
- Proper HTTP status codes

**NEW: test_e2e_flow.py - Create E2E integration test (TEST-14):**
```python
"""End-to-end integration test for document upload to borrower query flow."""
import pytest
from httpx import AsyncClient

@pytest.mark.integration
@pytest.mark.asyncio
async def test_upload_to_extraction_flow(client: AsyncClient, mock_gemini_client):
    """Test complete flow: upload document -> process -> extract borrowers -> query."""
    # 1. Upload document
    response = await client.post(
        "/api/documents",
        files={"file": ("test.pdf", b"PDF content", "application/pdf")}
    )
    assert response.status_code == 201
    doc_id = response.json()["id"]

    # 2. Verify processing completed
    status_response = await client.get(f"/api/documents/{doc_id}/status")
    assert status_response.json()["status"] in ["completed", "failed"]

    # 3. Query borrowers (if extraction succeeded)
    if status_response.json()["status"] == "completed":
        borrowers_response = await client.get("/api/borrowers")
        assert borrowers_response.status_code == 200
```

Mark integration tests with `@pytest.mark.integration` for selective running.
  </action>
  <verify>
```bash
cd backend
pytest tests/extraction/ tests/unit/test_borrower_repository.py tests/unit/test_borrower_routes.py tests/integration/test_e2e_flow.py -v
pytest --cov=src --cov-report=term-missing --cov-fail-under=80
```
All tests pass and coverage is >= 80%.
  </verify>
  <done>
Extraction tests, API route tests, and E2E integration test added. Coverage validated at 80%+.
  </done>
</task>

<task type="auto">
  <name>Task 4: Add Sample Document Integration Test and Frontend Smoke Tests</name>
  <files>
    backend/tests/integration/test_sample_documents.py
    frontend/e2e/smoke.spec.ts
    frontend/package.json
    backend/tests/fixtures/
  </files>
  <action>
Create sample document integration test and frontend smoke tests to cover TEST-15 and TEST-16.

**Part A: Sample Loan Documents Integration Test (TEST-15)**

Create `backend/tests/integration/test_sample_documents.py`:
```python
"""Integration tests using sample loan document corpus.

These tests validate the extraction pipeline against real-world document patterns.
Requires sample documents in tests/fixtures/sample_docs/ directory.
"""
import pytest
from pathlib import Path

SAMPLE_DOCS_DIR = Path(__file__).parent.parent / "fixtures" / "sample_docs"

@pytest.mark.integration
@pytest.mark.skipif(
    not SAMPLE_DOCS_DIR.exists(),
    reason="Sample documents directory not found"
)
class TestSampleDocumentExtraction:
    """Test extraction pipeline with sample loan documents."""

    @pytest.mark.asyncio
    async def test_sample_loan_document_extraction(
        self, client, mock_gemini_client
    ):
        """Test extraction from a sample loan document produces expected fields."""
        sample_pdf = SAMPLE_DOCS_DIR / "sample_loan_application.pdf"
        if not sample_pdf.exists():
            pytest.skip("Sample loan document not available")

        with open(sample_pdf, "rb") as f:
            response = await client.post(
                "/api/documents",
                files={"file": ("sample.pdf", f, "application/pdf")}
            )

        assert response.status_code == 201
        doc_data = response.json()
        assert "id" in doc_data

        # Verify processing completed
        status = await client.get(f"/api/documents/{doc_data['id']}/status")
        assert status.json()["status"] in ["completed", "processing", "failed"]

    @pytest.mark.asyncio
    async def test_multi_borrower_document(self, client, mock_gemini_client):
        """Test document with multiple borrowers extracts all."""
        # Uses mock - validates the pipeline handles multi-borrower scenario
        pass

    @pytest.mark.asyncio
    async def test_document_with_income_records(self, client, mock_gemini_client):
        """Test document with income info extracts income records."""
        pass
```

Create `backend/tests/fixtures/sample_docs/.gitkeep` to establish the directory.

Note: Actual sample documents should be added by user (cannot commit PII-containing docs).

**Part B: Frontend Smoke Tests (TEST-16)**

First, add Playwright to frontend:
```bash
cd frontend
npm install -D @playwright/test
npx playwright install chromium
```

Update `frontend/package.json` scripts:
```json
{
  "scripts": {
    "test:e2e": "playwright test",
    "test:e2e:ui": "playwright test --ui"
  }
}
```

Create `frontend/playwright.config.ts`:
```typescript
import { defineConfig, devices } from '@playwright/test';

export default defineConfig({
  testDir: './e2e',
  fullyParallel: true,
  forbidOnly: !!process.env.CI,
  retries: process.env.CI ? 2 : 0,
  workers: process.env.CI ? 1 : undefined,
  reporter: 'html',
  use: {
    baseURL: 'http://localhost:3000',
    trace: 'on-first-retry',
  },
  projects: [
    {
      name: 'chromium',
      use: { ...devices['Desktop Chrome'] },
    },
  ],
  webServer: {
    command: 'npm run dev',
    url: 'http://localhost:3000',
    reuseExistingServer: !process.env.CI,
  },
});
```

Create `frontend/e2e/smoke.spec.ts`:
```typescript
import { test, expect } from '@playwright/test';

test.describe('Dashboard Smoke Tests', () => {
  test('dashboard loads successfully', async ({ page }) => {
    await page.goto('/');

    // Verify page title or main heading
    await expect(page.locator('h1')).toBeVisible();

    // Verify key navigation elements
    await expect(page.getByRole('navigation')).toBeVisible();
  });

  test('borrowers page loads', async ({ page }) => {
    await page.goto('/borrowers');

    // Should show borrowers table or empty state
    await expect(
      page.getByText(/borrowers|no data/i)
    ).toBeVisible();
  });
});

test.describe('Document Upload Smoke Tests', () => {
  test('upload page accessible', async ({ page }) => {
    await page.goto('/documents');

    // Verify upload area is present
    await expect(
      page.getByRole('button', { name: /upload/i })
        .or(page.locator('[type="file"]'))
        .or(page.getByText(/drag.*drop/i))
    ).toBeVisible();
  });

  test('upload form accepts file selection', async ({ page }) => {
    await page.goto('/documents');

    // Find file input
    const fileInput = page.locator('input[type="file"]');
    if (await fileInput.count() > 0) {
      await expect(fileInput).toBeEnabled();
    }
  });
});
```
  </action>
  <verify>
```bash
# Verify sample docs test file exists
test -f backend/tests/integration/test_sample_documents.py && echo "Sample docs test: OK"

# Verify frontend smoke tests
test -f frontend/e2e/smoke.spec.ts && echo "Frontend smoke tests: OK"
test -f frontend/playwright.config.ts && echo "Playwright config: OK"

# Run frontend smoke tests (requires dev server)
cd frontend
npm run test:e2e -- --reporter=list || echo "Smoke tests may need manual verification with running server"
```
  </verify>
  <done>
Sample document integration test structure created (TEST-15) and frontend smoke tests with Playwright configured (TEST-16)
  </done>
</task>

</tasks>

<verification>
1. pytest-xdist installed and available
2. Coverage configuration in pyproject.toml with fail_under=80
3. All test files updated with expanded coverage
4. `pytest --cov=src --cov-fail-under=80` passes
5. Tests cover requirements TEST-01 through TEST-16
6. Sample document integration test exists (TEST-15)
7. Frontend smoke tests configured with Playwright (TEST-16)
</verification>

<success_criteria>
- pytest coverage report shows >80% backend coverage
- All unit tests for Docling, document service, GCS client, models pass
- All extraction tests pass (LLM client, extractor, validation)
- All API route tests pass (documents, borrowers)
- E2E integration test validates upload-to-query flow
- Tests can run in parallel with pytest-xdist
- Sample document integration test structure in place (TEST-15)
- Frontend smoke tests pass with Playwright (TEST-16)
</success_criteria>

<output>
After completion, create `.planning/phases/07-documentation-testing/07-04-SUMMARY.md`
</output>
