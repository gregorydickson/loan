---
phase: 08-wire-document-to-extraction-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - backend/src/ingestion/document_service.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Uploading a document triggers borrower extraction after Docling processing"
    - "Extracted borrowers are persisted to database with all relationships"
    - "SSN is hashed before storage (PII protection)"
    - "Extraction failures do not prevent document completion"
  artifacts:
    - path: "backend/src/ingestion/document_service.py"
      provides: "upload() calls extractor and _persist_borrower method"
      contains: "self.borrower_extractor.extract"
      min_lines: 300
  key_links:
    - from: "backend/src/ingestion/document_service.py"
      to: "backend/src/extraction/extractor.py"
      via: "calls extract() with DocumentContent"
      pattern: "self.borrower_extractor.extract\\("
    - from: "backend/src/ingestion/document_service.py"
      to: "backend/src/storage/repositories.py"
      via: "calls borrower_repository.create()"
      pattern: "self.borrower_repository.create\\("
---

<objective>
Integrate BorrowerExtractor into DocumentService.upload() to extract and persist borrowers after Docling processing.

Purpose: This is the core integration that closes the Phase 2 -> Phase 3 -> Phase 4 gap. After Docling extracts text from a document, BorrowerExtractor will find borrower data, and that data will be saved to the database.

Output: DocumentService.upload() that extracts borrowers and persists them with SSN hashing and proper error handling.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/08-wire-document-to-extraction-pipeline/08-RESEARCH.md
@.planning/phases/08-wire-document-to-extraction-pipeline/08-01-SUMMARY.md

# Key source files
@backend/src/ingestion/document_service.py
@backend/src/extraction/extractor.py
@backend/src/storage/repositories.py
@backend/src/storage/models.py
@backend/src/models/borrower.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add _persist_borrower helper method to DocumentService</name>
  <files>backend/src/ingestion/document_service.py</files>
  <action>
Add a private method to convert Pydantic BorrowerRecord to SQLAlchemy models and persist via BorrowerRepository.

1. Add required imports at top of file:
   ```python
   import hashlib
   import logging
   from decimal import Decimal

   from src.models.borrower import BorrowerRecord
   from src.storage.models import (
       AccountNumber,
       Borrower,
       Document,
       DocumentStatus,
       IncomeRecord as IncomeRecordModel,
       SourceReference as SourceReferenceModel,
   )
   ```

2. Add logger after imports:
   ```python
   logger = logging.getLogger(__name__)
   ```

3. Add _persist_borrower method to DocumentService class:
   ```python
   async def _persist_borrower(
       self,
       record: BorrowerRecord,
       document_id: UUID,
   ) -> Borrower:
       """Convert Pydantic BorrowerRecord to SQLAlchemy Borrower and persist.

       Args:
           record: Extracted borrower data from BorrowerExtractor
           document_id: Source document UUID for reference

       Returns:
           Persisted Borrower with all relationships
       """
       # Hash SSN for storage (never store raw SSN - PII protection)
       ssn_hash = None
       if record.ssn:
           ssn_hash = hashlib.sha256(record.ssn.encode()).hexdigest()

       # Convert address to JSON string
       address_json = None
       if record.address:
           address_json = record.address.model_dump_json()

       # Create SQLAlchemy Borrower model
       borrower = Borrower(
           id=record.id,
           name=record.name,
           ssn_hash=ssn_hash,
           address_json=address_json,
           confidence_score=Decimal(str(record.confidence_score)),
       )

       # Convert income records
       income_records = [
           IncomeRecordModel(
               amount=income.amount,
               period=income.period,
               year=income.year,
               source_type=income.source_type,
               employer=income.employer,
           )
           for income in record.income_history
       ]

       # Convert account numbers (both bank accounts and loan numbers)
       account_numbers = [
           AccountNumber(number=acct, account_type="bank")
           for acct in record.account_numbers
       ] + [
           AccountNumber(number=loan, account_type="loan")
           for loan in record.loan_numbers
       ]

       # Convert source references
       source_references = [
           SourceReferenceModel(
               document_id=src.document_id,
               page_number=src.page_number,
               section=src.section,
               snippet=src.snippet,
           )
           for src in record.sources
       ]

       # Persist via repository (handles transaction)
       return await self.borrower_repository.create(
           borrower=borrower,
           income_records=income_records,
           account_numbers=account_numbers,
           source_references=source_references,
       )
   ```

NOTE: There's a naming collision with IncomeRecord (Pydantic) and IncomeRecord (SQLAlchemy). Import SQLAlchemy version as IncomeRecordModel and SourceReferenceModel.
  </action>
  <verify>
Run: `cd /Users/gregorydickson/stackpoint/loan/backend && python -c "from src.ingestion.document_service import DocumentService; print('Import ok')"`
Expected: Import succeeds with no errors
  </verify>
  <done>
- _persist_borrower method added to DocumentService
- SSN hashing implemented with SHA-256
- Address serialized to JSON
- Income records, account numbers, and source references converted
- Method calls borrower_repository.create()
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate extraction into upload() method</name>
  <files>backend/src/ingestion/document_service.py</files>
  <action>
Modify the upload() method to call BorrowerExtractor after successful Docling processing, then persist extracted borrowers.

Find the try block in upload() that calls docling_processor.process_bytes() (around line 199-219). After successful processing and BEFORE the refreshed = await self.repository.get_by_id(document_id) line, add extraction and persistence logic:

```python
# 7. Process document with Docling (synchronous)
try:
    result = self.docling_processor.process_bytes(content, filename)
    await self.update_processing_result(
        document_id,
        success=True,
        page_count=result.page_count,
    )

    # 8. Extract borrowers from processed document
    try:
        extraction_result = self.borrower_extractor.extract(
            document=result,
            document_id=document_id,
            document_name=filename,
        )

        # 9. Persist extracted borrowers
        for borrower_record in extraction_result.borrowers:
            try:
                await self._persist_borrower(borrower_record, document_id)
                logger.info(
                    "Persisted borrower '%s' from document %s",
                    borrower_record.name,
                    document_id,
                )
            except Exception as e:
                logger.warning(
                    "Failed to persist borrower '%s': %s",
                    borrower_record.name,
                    str(e),
                )

        # Log extraction summary
        logger.info(
            "Extraction complete for document %s: %d borrowers, %d validation errors, %d consistency warnings",
            document_id,
            len(extraction_result.borrowers),
            len(extraction_result.validation_errors),
            len(extraction_result.consistency_warnings),
        )

    except Exception as e:
        # Extraction failure should not fail the document - log and continue
        # Document is COMPLETED (Docling worked), extraction just didn't find borrowers
        logger.warning(
            "Extraction failed for document %s: %s. Document marked completed anyway.",
            document_id,
            str(e),
        )

    # Refresh document to get updated status
    refreshed = await self.repository.get_by_id(document_id)
    if refreshed is not None:
        document = refreshed
except DocumentProcessingError as e:
    # ... existing error handling
```

Key design decisions:
1. Extraction errors are logged but don't fail the upload (partial success is better than failure)
2. Individual borrower persistence errors are caught (save what we can)
3. Document status is COMPLETED if Docling succeeded, regardless of extraction outcome
  </action>
  <verify>
Run: `cd /Users/gregorydickson/stackpoint/loan/backend && python -c "from src.ingestion.document_service import DocumentService; print(hasattr(DocumentService, '_persist_borrower'))"`
Expected: "True"

Run: `cd /Users/gregorydickson/stackpoint/loan/backend && python -m pytest tests/integration/test_e2e_flow.py -v --tb=short 2>&1 | tail -20`
Expected: Tests pass (mocked extractor returns empty list, so no borrowers persisted but no errors)
  </verify>
  <done>
- upload() calls self.borrower_extractor.extract() after Docling success
- Each extracted borrower passed to _persist_borrower()
- Extraction errors logged but don't fail document
- Individual persistence errors logged but don't fail extraction
- Logging provides visibility into extraction results
  </done>
</task>

<task type="auto">
  <name>Task 3: Update docstring and class-level documentation</name>
  <files>backend/src/ingestion/document_service.py</files>
  <action>
Update the module docstring and DocumentService class docstring to reflect the full pipeline.

1. Update module docstring at top of file:
   ```python
   """Document service orchestrating upload and extraction flow.

   Handles:
   - File validation (type, size)
   - File hash computation for duplicate detection
   - GCS upload
   - Database record creation
   - Docling document processing (synchronous)
   - Borrower extraction via LLM
   - Borrower persistence with source attribution
   """
   ```

2. Update DocumentService class docstring:
   ```python
   class DocumentService:
       """Orchestrates document upload, processing, and extraction.

       Upload workflow:
       1. Validate file (type, size)
       2. Compute file hash (SHA-256)
       3. Check for duplicate (reject if exists)
       4. Create database record (PENDING status)
       5. Upload to GCS
       6. Process document with Docling
       7. Update status to COMPLETED/FAILED
       8. Extract borrowers via BorrowerExtractor
       9. Persist extracted borrowers with source references
       10. Return document with final status

       Note: Extraction failures are logged but don't fail the upload.
       A document with successful Docling processing is COMPLETED even
       if no borrowers were extracted.
       """
   ```
  </action>
  <verify>
Run: `cd /Users/gregorydickson/stackpoint/loan/backend && python -c "from src.ingestion.document_service import DocumentService; print(DocumentService.__doc__[:50])"`
Expected: First 50 chars of updated docstring
  </verify>
  <done>
- Module docstring reflects full pipeline
- Class docstring lists all 10 workflow steps
- Error handling behavior documented
  </done>
</task>

</tasks>

<verification>
All verification steps:
1. `python -c "from src.ingestion.document_service import DocumentService"` - imports work
2. `pytest tests/integration/test_e2e_flow.py -v` - all E2E tests pass
3. `pytest tests/integration/test_documents_api.py -v` - all document API tests pass
4. `grep -n "borrower_extractor.extract" backend/src/ingestion/document_service.py` - extraction call exists
5. `grep -n "hashlib.sha256" backend/src/ingestion/document_service.py` - SSN hashing exists
</verification>

<success_criteria>
- upload() calls BorrowerExtractor.extract() after Docling processing
- _persist_borrower() converts Pydantic to SQLAlchemy and saves
- SSN is hashed (never stored raw)
- Extraction errors logged but don't fail document upload
- All existing integration tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/08-wire-document-to-extraction-pipeline/08-02-SUMMARY.md`
</output>
