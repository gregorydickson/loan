---
phase: 03-llm-extraction-validation
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/extraction/complexity_classifier.py
  - backend/src/extraction/prompts.py
  - backend/src/extraction/chunker.py
  - backend/tests/extraction/test_complexity_classifier.py
  - backend/tests/extraction/test_chunker.py
autonomous: true

must_haves:
  truths:
    - "Classifier identifies simple single-borrower documents as STANDARD"
    - "Classifier identifies multi-borrower documents as COMPLEX"
    - "Classifier detects poor scan quality indicators"
    - "Classifier detects handwritten content markers"
    - "Extraction prompts render document text safely (escape braces)"
    - "Chunker splits large documents with paragraph-aware boundaries"
    - "Chunker includes overlap between chunks to avoid splitting entities"
  artifacts:
    - path: "backend/src/extraction/complexity_classifier.py"
      provides: "ComplexityClassifier with classify() method"
      exports: ["ComplexityClassifier", "ComplexityLevel", "ComplexityAssessment"]
      min_lines: 80
    - path: "backend/src/extraction/prompts.py"
      provides: "Prompt templates for extraction"
      exports: ["EXTRACTION_SYSTEM_PROMPT", "build_extraction_prompt"]
      min_lines: 40
    - path: "backend/src/extraction/chunker.py"
      provides: "DocumentChunker with chunk() method"
      exports: ["DocumentChunker", "TextChunk"]
      min_lines: 60
  key_links:
    - from: "backend/src/extraction/complexity_classifier.py"
      to: "re module"
      via: "regex pattern matching"
      pattern: "re\\.search|re\\.findall"
    - from: "backend/src/extraction/chunker.py"
      to: "document text"
      via: "paragraph boundary detection"
      pattern: "rfind.*\\\\n\\\\n"
---

<objective>
Create the document preprocessing components: complexity classification for model routing, prompt templates for extraction, and document chunking for large texts.

Purpose: Prepare documents for LLM extraction - classify complexity to pick the right model, chunk large docs to avoid truncation
Output: ComplexityClassifier, prompt templates, DocumentChunker - all prerequisites for the extraction orchestrator
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-llm-extraction--validation/03-RESEARCH.md
@backend/src/models/borrower.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ComplexityClassifier for model routing</name>
  <files>
    backend/src/extraction/complexity_classifier.py
    backend/tests/extraction/test_complexity_classifier.py
  </files>
  <action>
Create `complexity_classifier.py` with:

1. `ComplexityLevel` enum (str, Enum):
   - `STANDARD = "standard"` - Use Flash model
   - `COMPLEX = "complex"` - Use Pro model

2. `ComplexityAssessment` dataclass:
   - `level: ComplexityLevel`
   - `reasons: list[str]` - Why this level was assigned
   - `page_count: int`
   - `estimated_borrowers: int`
   - `has_handwritten: bool`
   - `has_poor_quality: bool`

3. `ComplexityClassifier` class with:
   - Class constants for regex patterns:
     - `MULTI_BORROWER_PATTERNS`: ["co-borrower", "joint\\s+applicant", "spouse", "borrower\\s+2", "second\\s+borrower"]
     - `POOR_QUALITY_PATTERNS`: ["\\[illegible\\]", "\\[unclear\\]", "\\?\\?\\?", "[^\\w\\s]{5,}"]
     - `HANDWRITTEN_PATTERNS`: ["\\[handwritten\\]", "signature:", "signed:"]

   - `classify(self, text: str, page_count: int) -> ComplexityAssessment`:
     - Count multi-borrower indicators (any pattern match = +1 estimated borrower)
     - Check page count (>10 = complex)
     - Count poor quality indicators (>3 = poor quality)
     - Check for handwritten content (any match = handwritten)
     - Level is COMPLEX if: estimated_borrowers > 1 OR page_count > 10 OR has_poor_quality OR has_handwritten
     - Build reasons list explaining the classification

Unit tests (test_complexity_classifier.py):
- `test_simple_document_is_standard` - Single borrower, short doc
- `test_multi_borrower_is_complex` - Text with "co-borrower"
- `test_large_document_is_complex` - page_count > 10
- `test_poor_quality_is_complex` - Multiple [illegible] markers
- `test_handwritten_is_complex` - Text with "signature:"
- `test_reasons_populated` - Verify reasons list explains classification
  </action>
  <verify>
`cd backend && python -m pytest tests/extraction/test_complexity_classifier.py -v` passes
  </verify>
  <done>
ComplexityClassifier correctly routes simple docs to STANDARD (Flash) and complex docs to COMPLEX (Pro)
  </done>
</task>

<task type="auto">
  <name>Task 2: Create extraction prompt templates</name>
  <files>
    backend/src/extraction/prompts.py
  </files>
  <action>
Create `prompts.py` with:

1. `EXTRACTION_SYSTEM_PROMPT` constant (multi-line string):
```
You are a loan document data extraction specialist. Extract borrower information from loan documents with high accuracy.

Your task:
1. Identify all borrowers mentioned in the document
2. Extract their personal information (name, SSN, address, phone, email)
3. Extract income history with amounts, periods, and sources
4. Extract account and loan numbers

Rules:
- Extract data exactly as it appears - do not infer or guess
- If a field is unclear or missing, omit it (return null)
- SSN format: XXX-XX-XXXX
- Income amounts: numeric only, no currency symbols
- Multiple borrowers should be separate records

Quality indicators to note:
- Mark data from handwritten sections with lower confidence
- Note if scanned text appears unclear
```

2. `EXTRACTION_USER_PROMPT_TEMPLATE` constant:
```
Extract all borrower information from this loan document:

---
{document_text}
---

Return a JSON object with the extracted borrowers.
```

3. `build_extraction_prompt(document_text: str) -> str` function:
   - Escape curly braces in document text: `safe_text = document_text.replace("{", "{{").replace("}", "}}")`
   - Return `EXTRACTION_USER_PROMPT_TEMPLATE.format(document_text=safe_text)`

This handles special characters safely (EXTRACT-18 requirement).
  </action>
  <verify>
`python -c "from src.extraction.prompts import EXTRACTION_SYSTEM_PROMPT, build_extraction_prompt; print(len(EXTRACTION_SYSTEM_PROMPT) > 100, 'test {bracket}' not in build_extraction_prompt('test {bracket}'))"` prints `True True`
  </verify>
  <done>
Prompt templates created with safe brace escaping for document text injection
  </done>
</task>

<task type="auto">
  <name>Task 3: Create DocumentChunker with overlap</name>
  <files>
    backend/src/extraction/chunker.py
    backend/tests/extraction/test_chunker.py
  </files>
  <action>
Create `chunker.py` with:

1. `TextChunk` dataclass:
   - `text: str` - Chunk content
   - `start_char: int` - Start position in original document
   - `end_char: int` - End position in original document
   - `chunk_index: int` - 0-based chunk index
   - `total_chunks: int` - Total number of chunks

2. `DocumentChunker` class:
   - `__init__(self, max_chars: int = 16000, overlap_chars: int = 800)`:
     - 16000 chars ~ 4000 tokens (EXTRACT-20: 4000 tokens, 200 overlap)
     - 800 chars ~ 200 tokens overlap

   - `chunk(self, text: str) -> list[TextChunk]`:
     - If `len(text) <= max_chars`: return single chunk
     - Otherwise, split with paragraph-aware boundaries:
       - Start at position 0
       - Find end at `start + max_chars`
       - Look for `\n\n` in last 20% of chunk, use that as boundary if found
       - Create TextChunk with position metadata
       - Move start forward by `(end - overlap_chars)` for overlap
       - Continue until end of text
     - Update `total_chunks` on all chunks after loop

Unit tests (test_chunker.py):
- `test_small_text_single_chunk` - Text < max_chars returns 1 chunk
- `test_large_text_multiple_chunks` - Long text splits into multiple
- `test_chunks_have_overlap` - Adjacent chunks share text at boundary
- `test_paragraph_boundary_preferred` - Split happens at \n\n when nearby
- `test_chunk_metadata_accurate` - start_char, end_char, indexes correct
  </action>
  <verify>
`cd backend && python -m pytest tests/extraction/test_chunker.py -v` passes
  </verify>
  <done>
DocumentChunker splits large documents with 200-token overlap and paragraph-aware boundaries
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.extraction.complexity_classifier import ComplexityClassifier, ComplexityLevel"` - Import succeeds
2. `python -c "from src.extraction.prompts import EXTRACTION_SYSTEM_PROMPT, build_extraction_prompt"` - Import succeeds
3. `python -c "from src.extraction.chunker import DocumentChunker, TextChunk"` - Import succeeds
4. `python -m pytest tests/extraction/test_complexity_classifier.py tests/extraction/test_chunker.py -v` - All tests pass
</verification>

<success_criteria>
- ComplexityClassifier routes documents to STANDARD or COMPLEX based on heuristics
- Prompt templates safely handle special characters in document text
- DocumentChunker splits large docs with 200-token overlap at paragraph boundaries
- EXTRACT-11 through EXTRACT-21 (partial) requirements addressed
- 10+ unit tests passing
</success_criteria>

<output>
After completion, create `.planning/phases/03-llm-extraction--validation/03-02-SUMMARY.md`
</output>
