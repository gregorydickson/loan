---
phase: 19-production-deployment-verification
plan: 03
type: execute
wave: 2
depends_on: ["19-01"]
files_modified: []
autonomous: true

must_haves:
  truths:
    - "GPU OCR service is deployed to Cloud Run with L4 GPU"
    - "GPU service has scale-to-zero configured (min-instances=0)"
    - "GPU service health endpoint responds (may need auth token)"
  artifacts:
    - path: "Cloud Run service: lightonocr-gpu"
      provides: "GPU-accelerated OCR service deployment"
      verification: "gcloud run services describe lightonocr-gpu --region=us-central1"
  key_links:
    - from: "lightonocr-gpu"
      to: "nvidia-l4 GPU"
      via: "--gpu 1 --gpu-type nvidia-l4"
      pattern: "nvidia.com/gpu"
    - from: "loan-backend-prod"
      to: "lightonocr-gpu"
      via: "service-to-service auth"
      pattern: "Authorization.*Bearer"
---

<objective>
Deploy GPU OCR service (LightOnOCR) to Cloud Run with L4 GPU and scale-to-zero configuration.

Purpose: GPU service handles scanned document OCR. Scale-to-zero minimizes costs when not in use.
Output: GPU service running at https://lightonocr-gpu-*.run.app with L4 GPU and min-instances=0.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/19-production-deployment-verification/19-RESEARCH.md
@infrastructure/cloudbuild/gpu-cloudbuild.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Check GPU service deployment status</name>
  <files>None - verification only</files>
  <action>
    Check if GPU service is already deployed:

    1. Check if lightonocr-gpu service exists:
       ```bash
       gcloud run services describe lightonocr-gpu --region=us-central1 --format="value(status.url)" 2>/dev/null
       ```

    2. If service exists, verify GPU configuration:
       ```bash
       gcloud run services describe lightonocr-gpu --region=us-central1 \
           --format="yaml(spec.template.spec.containers[0].resources)"
       ```
       Expected: nvidia.com/gpu: "1"

    3. Check scale-to-zero configuration:
       ```bash
       gcloud run services describe lightonocr-gpu --region=us-central1 \
           --format="value(spec.template.metadata.annotations.'autoscaling.knative.dev/minScale')"
       ```
       Expected: 0

    4. Record deployment status for Task 2 decision.
  </action>
  <verify>gcloud commands execute successfully, deployment status is known</verify>
  <done>GPU service deployment status documented with GPU and scaling config</done>
</task>

<task type="auto">
  <name>Task 2: Deploy GPU service via CloudBuild (if needed)</name>
  <files>None - uses existing CloudBuild config</files>
  <action>
    Deploy GPU service if not already deployed:

    **IMPORTANT:** GPU build takes 30-60 minutes due to vLLM base image (~8GB) and model download (~2GB).

    1. If GPU service NOT deployed:
       ```bash
       cd /Users/gregorydickson/stackpoint/loan

       # Start GPU build (runs in background on CloudBuild)
       gcloud builds submit \
           --config=infrastructure/cloudbuild/gpu-cloudbuild.yaml \
           --substitutions=SHORT_SHA=$(git rev-parse --short HEAD) \
           --async \
           .
       ```

    2. Monitor build progress (optional - can check later):
       ```bash
       # Get build ID
       BUILD_ID=$(gcloud builds list --limit=1 --format="value(id)")
       echo "Build ID: $BUILD_ID"

       # Stream logs (or check status periodically)
       gcloud builds log $BUILD_ID --stream
       ```

    3. If GPU service IS deployed and correctly configured, skip to Task 3.

    4. After build completes (may need to wait or check later):
       ```bash
       gcloud run services describe lightonocr-gpu --region=us-central1 --format="value(status.url)"
       ```

    This satisfies DEPLOY-04. Note build may complete after plan execution - that's OK for verification plan.
  </action>
  <verify>
    Either: Service already exists with correct GPU config, OR build submitted successfully (check with gcloud builds list)
  </verify>
  <done>GPU service deployed or build submitted for deployment</done>
</task>

<task type="auto">
  <name>Task 3: Verify GPU service configuration and health</name>
  <files>None - verification only</files>
  <action>
    Verify GPU service is correctly configured (after build completes):

    1. Get GPU service URL:
       ```bash
       GPU_URL=$(gcloud run services describe lightonocr-gpu --region=us-central1 --format="value(status.url)" 2>/dev/null)
       if [ -z "$GPU_URL" ]; then
           echo "GPU service not yet deployed - build may still be running"
           echo "Check: gcloud builds list --limit=1"
           exit 0  # Not a failure - build takes 30-60 min
       fi
       echo "GPU URL: $GPU_URL"
       ```

    2. Verify GPU configuration:
       ```bash
       GPU_COUNT=$(gcloud run services describe lightonocr-gpu --region=us-central1 \
           --format="value(spec.template.spec.containers[0].resources.limits.'nvidia.com/gpu')")
       echo "GPU Count: $GPU_COUNT"  # Expected: 1
       ```

    3. Verify scale-to-zero:
       ```bash
       MIN_INSTANCES=$(gcloud run services describe lightonocr-gpu --region=us-central1 \
           --format="value(spec.template.metadata.annotations.'autoscaling.knative.dev/minScale')")
       echo "Min Instances: $MIN_INSTANCES"  # Expected: 0
       ```

    4. Test health endpoint (requires authentication):
       ```bash
       TOKEN=$(gcloud auth print-identity-token)
       # Use longer timeout for cold start (up to 60s)
       curl -s --max-time 60 -H "Authorization: Bearer ${TOKEN}" "${GPU_URL}/health" || echo "Cold start in progress or health endpoint unavailable"
       ```
       Note: GPU service may take 10-40 seconds on cold start. Health check may timeout initially.

    5. If health check fails, check logs:
       ```bash
       gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=lightonocr-gpu" \
           --limit=10 --format="table(timestamp,textPayload)"
       ```

    This satisfies DEPLOY-04 verification and partial DEPLOY-06.
  </action>
  <verify>
    GPU service has nvidia.com/gpu=1, min-instances=0, and responds to authenticated health check (or build still in progress)
  </verify>
  <done>GPU service verified with L4 GPU and scale-to-zero configuration</done>
</task>

</tasks>

<verification>
After completing all tasks:

1. GPU service appears in `gcloud run services list`
2. GPU configuration shows nvidia-l4 GPU
3. Scale-to-zero is enabled (min-instances=0)
4. Health check responds (with auth token)

Commands to verify:
```bash
gcloud run services list --region=us-central1 | grep lightonocr-gpu
gcloud run services describe lightonocr-gpu --region=us-central1 \
    --format="yaml(spec.template.spec.containers[0].resources.limits)"
```

Note: If build was submitted async, check `gcloud builds list --limit=1` for status.
</verification>

<success_criteria>
- DEPLOY-04: GPU service deployed (or build in progress)
- GPU configured with nvidia-l4 (1 GPU)
- Scale-to-zero enabled (min-instances=0)
- Health endpoint accessible with authentication
</success_criteria>

<output>
After completion, create `.planning/phases/19-production-deployment-verification/19-03-SUMMARY.md` with:
- GPU service URL (if deployed)
- Build status (if still running)
- GPU configuration verified
- Scale-to-zero status
- Health check result
</output>
