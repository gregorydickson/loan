---
phase: 13-lightonocr-gpu-service
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/src/ocr/__init__.py
  - backend/src/ocr/lightonocr_client.py
  - backend/tests/unit/ocr/__init__.py
  - backend/tests/unit/ocr/test_lightonocr_client.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "LightOnOCRClient sends images to GPU service via vLLM OpenAI-compatible API"
    - "Client authenticates using OIDC ID token for Cloud Run"
    - "Client handles errors and returns extracted text"
  artifacts:
    - path: "backend/src/ocr/lightonocr_client.py"
      provides: "HTTP client for LightOnOCR GPU service"
      exports: ["LightOnOCRClient"]
    - path: "backend/tests/unit/ocr/test_lightonocr_client.py"
      provides: "Unit tests for LightOnOCRClient"
      min_lines: 100
  key_links:
    - from: "backend/src/ocr/lightonocr_client.py"
      to: "GPU service /v1/chat/completions"
      via: "httpx async POST"
      pattern: "/v1/chat/completions"
    - from: "backend/src/ocr/lightonocr_client.py"
      to: "google-auth"
      via: "id_token.fetch_id_token"
      pattern: "id_token\\.fetch_id_token"
---

<objective>
Create LightOnOCRClient for backend to communicate with GPU service

Purpose: Backend HTTP client that sends images to LightOnOCR GPU service and receives extracted text
Output: LightOnOCRClient class with OIDC authentication and unit tests
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-lightonocr-gpu-service/13-RESEARCH.md
@.planning/phases/13-lightonocr-gpu-service/13-CONTEXT.md
@backend/src/extraction/extraction_router.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create LightOnOCRClient</name>
  <files>backend/src/ocr/__init__.py, backend/src/ocr/lightonocr_client.py</files>
  <action>
Create the OCR module and LightOnOCRClient for communicating with the GPU service.

**1. Create backend/src/ocr/__init__.py:**
```python
"""OCR module for LightOnOCR GPU service integration."""

from src.ocr.lightonocr_client import LightOnOCRClient

__all__ = ["LightOnOCRClient"]
```

**2. Create backend/src/ocr/lightonocr_client.py:**

Key implementation details from RESEARCH.md:
- Use vLLM OpenAI-compatible chat completions API
- Authenticate with OIDC ID token for Cloud Run service-to-service
- Accept image bytes, return extracted text string
- Detect image content type (PNG vs JPEG)
- Base64 encode image in data URI format
- Use httpx async client with configurable timeout

```python
"""LightOnOCR GPU service client.

LOCR-06: LightOnOCRClient in backend communicates with GPU service via HTTP
"""

import base64
import logging
from typing import Literal

import httpx
from google.auth.transport.requests import Request as AuthRequest
from google.oauth2 import id_token

logger = logging.getLogger(__name__)


class LightOnOCRError(Exception):
    """Base exception for LightOnOCR client errors."""

    pass


class LightOnOCRClient:
    """Client for LightOnOCR GPU service using vLLM OpenAI-compatible API.

    LOCR-06: LightOnOCRClient in backend communicates with GPU service via HTTP
    LOCR-07: GPU service requires internal-only authentication (service account)

    Example:
        client = LightOnOCRClient(service_url="https://lightonocr-gpu-xxx.run.app")
        text = await client.extract_text(image_bytes)
    """

    MODEL_ID = "lightonai/LightOnOCR-2-1B"
    DEFAULT_TIMEOUT = 120.0  # 2 minutes for cold start + processing
    DEFAULT_MAX_TOKENS = 4096

    def __init__(
        self,
        service_url: str,
        timeout: float = DEFAULT_TIMEOUT,
        max_tokens: int = DEFAULT_MAX_TOKENS,
    ):
        """Initialize LightOnOCR client.

        Args:
            service_url: Cloud Run GPU service URL (e.g., https://lightonocr-gpu-xxx.run.app)
            timeout: Request timeout in seconds (default 120s for cold starts)
            max_tokens: Max tokens for OCR output (default 4096)
        """
        self.service_url = service_url.rstrip("/")
        self.timeout = timeout
        self.max_tokens = max_tokens
        self._id_token_cache: str | None = None

    def _get_id_token(self) -> str:
        """Get OIDC ID token for Cloud Run authentication.

        Uses google-auth library to fetch ID token for service-to-service auth.
        Token is cached but refreshed on each request for simplicity (POC).

        Returns:
            ID token string for Authorization header
        """
        return id_token.fetch_id_token(AuthRequest(), self.service_url)

    def _detect_content_type(self, image_bytes: bytes) -> Literal["image/png", "image/jpeg"]:
        """Detect image content type from magic bytes.

        Args:
            image_bytes: Raw image bytes

        Returns:
            MIME type string
        """
        if image_bytes[:8] == b"\x89PNG\r\n\x1a\n":
            return "image/png"
        if image_bytes[:2] == b"\xff\xd8":
            return "image/jpeg"
        # Default to JPEG for unknown formats
        return "image/jpeg"

    async def extract_text(self, image_bytes: bytes) -> str:
        """Extract text from image using LightOnOCR GPU service.

        LOCR-06: Communicates with GPU service via HTTP

        Args:
            image_bytes: PNG or JPEG image bytes

        Returns:
            Extracted text from the image

        Raises:
            LightOnOCRError: If extraction fails
        """
        if not image_bytes:
            raise LightOnOCRError("Empty image bytes provided")

        # Encode image as base64 data URI
        content_type = self._detect_content_type(image_bytes)
        base64_image = base64.b64encode(image_bytes).decode("utf-8")
        image_url = f"data:{content_type};base64,{base64_image}"

        # Build vLLM OpenAI-compatible request
        payload = {
            "model": self.MODEL_ID,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {"url": image_url},
                        }
                    ],
                }
            ],
            "max_tokens": self.max_tokens,
        }

        # Get auth token
        try:
            token = self._get_id_token()
        except Exception as e:
            logger.error("Failed to get ID token: %s", str(e))
            raise LightOnOCRError(f"Authentication failed: {str(e)}") from e

        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json",
        }

        # Make request to vLLM chat completions endpoint
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(
                    f"{self.service_url}/v1/chat/completions",
                    json=payload,
                    headers=headers,
                )

                if response.status_code != 200:
                    error_text = response.text[:500]  # Truncate for logging
                    logger.error(
                        "LightOnOCR request failed: status=%d, body=%s",
                        response.status_code,
                        error_text,
                    )
                    raise LightOnOCRError(
                        f"Request failed with status {response.status_code}: {error_text}"
                    )

                result = response.json()

        except httpx.TimeoutException as e:
            logger.error("LightOnOCR request timed out: %s", str(e))
            raise LightOnOCRError(f"Request timed out after {self.timeout}s") from e
        except httpx.RequestError as e:
            logger.error("LightOnOCR request error: %s", str(e))
            raise LightOnOCRError(f"Request failed: {str(e)}") from e

        # Extract text from vLLM response
        try:
            text = result["choices"][0]["message"]["content"]
            logger.info(
                "LightOnOCR extracted %d characters from image",
                len(text),
            )
            return text
        except (KeyError, IndexError) as e:
            logger.error("Unexpected response format: %s", result)
            raise LightOnOCRError(f"Invalid response format: {str(e)}") from e

    async def health_check(self) -> bool:
        """Check if GPU service is healthy.

        Returns:
            True if service is healthy, False otherwise
        """
        try:
            token = self._get_id_token()
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(
                    f"{self.service_url}/health",
                    headers={"Authorization": f"Bearer {token}"},
                )
                return response.status_code == 200
        except Exception as e:
            logger.warning("Health check failed: %s", str(e))
            return False
```
  </action>
  <verify>
1. `python -c "from src.ocr import LightOnOCRClient"` succeeds (from backend/ directory)
2. `grep "id_token.fetch_id_token" backend/src/ocr/lightonocr_client.py` finds OIDC auth
3. `grep "/v1/chat/completions" backend/src/ocr/lightonocr_client.py` finds API endpoint
  </verify>
  <done>
- backend/src/ocr/__init__.py exports LightOnOCRClient
- backend/src/ocr/lightonocr_client.py implements async HTTP client with OIDC auth
- Client uses vLLM OpenAI-compatible chat completions API
  </done>
</task>

<task type="auto">
  <name>Task 2: Create unit tests for LightOnOCRClient</name>
  <files>backend/tests/unit/ocr/__init__.py, backend/tests/unit/ocr/test_lightonocr_client.py</files>
  <action>
Create comprehensive unit tests for LightOnOCRClient using mocks.

**1. Create backend/tests/unit/ocr/__init__.py:**
```python
"""Unit tests for OCR module."""
```

**2. Create backend/tests/unit/ocr/test_lightonocr_client.py:**

Test cases to cover:
- Successful text extraction
- Image content type detection (PNG vs JPEG)
- OIDC authentication (mock)
- HTTP error handling (4xx, 5xx)
- Timeout handling
- Invalid response format handling
- Health check success/failure
- Empty image bytes error

Use unittest.mock to mock:
- google.oauth2.id_token.fetch_id_token
- httpx.AsyncClient

```python
"""Unit tests for LightOnOCRClient.

Tests use mocks to avoid actual GPU service calls.
"""

import base64
from unittest.mock import AsyncMock, MagicMock, patch

import httpx
import pytest

from src.ocr.lightonocr_client import LightOnOCRClient, LightOnOCRError


# Sample image bytes (PNG magic header)
PNG_BYTES = b"\x89PNG\r\n\x1a\n" + b"\x00" * 100
JPEG_BYTES = b"\xff\xd8\xff" + b"\x00" * 100


class TestLightOnOCRClient:
    """Tests for LightOnOCRClient."""

    @pytest.fixture
    def client(self) -> LightOnOCRClient:
        """Create client for testing."""
        return LightOnOCRClient(
            service_url="https://lightonocr-gpu-test.run.app",
            timeout=30.0,
        )

    @pytest.fixture
    def mock_id_token(self):
        """Mock OIDC ID token."""
        with patch("src.ocr.lightonocr_client.id_token.fetch_id_token") as mock:
            mock.return_value = "mock-token-12345"
            yield mock

    def test_content_type_detection_png(self, client: LightOnOCRClient):
        """Test PNG content type detection."""
        assert client._detect_content_type(PNG_BYTES) == "image/png"

    def test_content_type_detection_jpeg(self, client: LightOnOCRClient):
        """Test JPEG content type detection."""
        assert client._detect_content_type(JPEG_BYTES) == "image/jpeg"

    def test_content_type_detection_unknown(self, client: LightOnOCRClient):
        """Test unknown format defaults to JPEG."""
        assert client._detect_content_type(b"unknown") == "image/jpeg"

    @pytest.mark.asyncio
    async def test_extract_text_success(self, client: LightOnOCRClient, mock_id_token):
        """Test successful text extraction."""
        mock_response = {
            "choices": [{"message": {"content": "Extracted loan document text"}}]
        }

        with patch("httpx.AsyncClient") as mock_client_class:
            mock_client = AsyncMock()
            mock_client.__aenter__.return_value = mock_client
            mock_client.__aexit__.return_value = None
            mock_client.post.return_value = MagicMock(
                status_code=200,
                json=lambda: mock_response,
            )
            mock_client_class.return_value = mock_client

            result = await client.extract_text(PNG_BYTES)

            assert result == "Extracted loan document text"
            mock_client.post.assert_called_once()
            call_args = mock_client.post.call_args
            assert "/v1/chat/completions" in call_args[0][0]
            assert call_args[1]["headers"]["Authorization"] == "Bearer mock-token-12345"

    @pytest.mark.asyncio
    async def test_extract_text_empty_bytes(self, client: LightOnOCRClient):
        """Test error on empty image bytes."""
        with pytest.raises(LightOnOCRError, match="Empty image bytes"):
            await client.extract_text(b"")

    @pytest.mark.asyncio
    async def test_extract_text_auth_failure(self, client: LightOnOCRClient):
        """Test authentication failure handling."""
        with patch("src.ocr.lightonocr_client.id_token.fetch_id_token") as mock:
            mock.side_effect = Exception("Auth failed")

            with pytest.raises(LightOnOCRError, match="Authentication failed"):
                await client.extract_text(PNG_BYTES)

    @pytest.mark.asyncio
    async def test_extract_text_http_error(self, client: LightOnOCRClient, mock_id_token):
        """Test HTTP error handling."""
        with patch("httpx.AsyncClient") as mock_client_class:
            mock_client = AsyncMock()
            mock_client.__aenter__.return_value = mock_client
            mock_client.__aexit__.return_value = None
            mock_client.post.return_value = MagicMock(
                status_code=500,
                text="Internal server error",
            )
            mock_client_class.return_value = mock_client

            with pytest.raises(LightOnOCRError, match="status 500"):
                await client.extract_text(PNG_BYTES)

    @pytest.mark.asyncio
    async def test_extract_text_timeout(self, client: LightOnOCRClient, mock_id_token):
        """Test timeout handling."""
        with patch("httpx.AsyncClient") as mock_client_class:
            mock_client = AsyncMock()
            mock_client.__aenter__.return_value = mock_client
            mock_client.__aexit__.return_value = None
            mock_client.post.side_effect = httpx.TimeoutException("Connection timed out")
            mock_client_class.return_value = mock_client

            with pytest.raises(LightOnOCRError, match="timed out"):
                await client.extract_text(PNG_BYTES)

    @pytest.mark.asyncio
    async def test_extract_text_request_error(self, client: LightOnOCRClient, mock_id_token):
        """Test request error handling."""
        with patch("httpx.AsyncClient") as mock_client_class:
            mock_client = AsyncMock()
            mock_client.__aenter__.return_value = mock_client
            mock_client.__aexit__.return_value = None
            mock_client.post.side_effect = httpx.RequestError("Connection failed")
            mock_client_class.return_value = mock_client

            with pytest.raises(LightOnOCRError, match="Request failed"):
                await client.extract_text(PNG_BYTES)

    @pytest.mark.asyncio
    async def test_extract_text_invalid_response(self, client: LightOnOCRClient, mock_id_token):
        """Test invalid response format handling."""
        mock_response = {"invalid": "response"}

        with patch("httpx.AsyncClient") as mock_client_class:
            mock_client = AsyncMock()
            mock_client.__aenter__.return_value = mock_client
            mock_client.__aexit__.return_value = None
            mock_client.post.return_value = MagicMock(
                status_code=200,
                json=lambda: mock_response,
            )
            mock_client_class.return_value = mock_client

            with pytest.raises(LightOnOCRError, match="Invalid response format"):
                await client.extract_text(PNG_BYTES)

    @pytest.mark.asyncio
    async def test_extract_text_base64_encoding(self, client: LightOnOCRClient, mock_id_token):
        """Test image is base64 encoded in request."""
        mock_response = {
            "choices": [{"message": {"content": "text"}}]
        }

        with patch("httpx.AsyncClient") as mock_client_class:
            mock_client = AsyncMock()
            mock_client.__aenter__.return_value = mock_client
            mock_client.__aexit__.return_value = None
            mock_client.post.return_value = MagicMock(
                status_code=200,
                json=lambda: mock_response,
            )
            mock_client_class.return_value = mock_client

            await client.extract_text(PNG_BYTES)

            # Verify base64 encoding in request payload
            call_args = mock_client.post.call_args
            payload = call_args[1]["json"]
            image_url = payload["messages"][0]["content"][0]["image_url"]["url"]
            assert image_url.startswith("data:image/png;base64,")
            # Verify it's valid base64
            base64_part = image_url.split(",")[1]
            decoded = base64.b64decode(base64_part)
            assert decoded == PNG_BYTES

    @pytest.mark.asyncio
    async def test_health_check_success(self, client: LightOnOCRClient, mock_id_token):
        """Test health check success."""
        with patch("httpx.AsyncClient") as mock_client_class:
            mock_client = AsyncMock()
            mock_client.__aenter__.return_value = mock_client
            mock_client.__aexit__.return_value = None
            mock_client.get.return_value = MagicMock(status_code=200)
            mock_client_class.return_value = mock_client

            result = await client.health_check()
            assert result is True

    @pytest.mark.asyncio
    async def test_health_check_failure(self, client: LightOnOCRClient, mock_id_token):
        """Test health check failure."""
        with patch("httpx.AsyncClient") as mock_client_class:
            mock_client = AsyncMock()
            mock_client.__aenter__.return_value = mock_client
            mock_client.__aexit__.return_value = None
            mock_client.get.return_value = MagicMock(status_code=503)
            mock_client_class.return_value = mock_client

            result = await client.health_check()
            assert result is False

    @pytest.mark.asyncio
    async def test_health_check_exception(self, client: LightOnOCRClient, mock_id_token):
        """Test health check with exception."""
        with patch("httpx.AsyncClient") as mock_client_class:
            mock_client = AsyncMock()
            mock_client.__aenter__.return_value = mock_client
            mock_client.__aexit__.return_value = None
            mock_client.get.side_effect = Exception("Network error")
            mock_client_class.return_value = mock_client

            result = await client.health_check()
            assert result is False

    def test_service_url_trailing_slash(self):
        """Test service URL trailing slash is stripped."""
        client = LightOnOCRClient(service_url="https://example.run.app/")
        assert client.service_url == "https://example.run.app"

    def test_custom_timeout(self):
        """Test custom timeout configuration."""
        client = LightOnOCRClient(service_url="https://example.run.app", timeout=60.0)
        assert client.timeout == 60.0

    def test_custom_max_tokens(self):
        """Test custom max_tokens configuration."""
        client = LightOnOCRClient(service_url="https://example.run.app", max_tokens=8192)
        assert client.max_tokens == 8192
```
  </action>
  <verify>
1. Run tests: `cd backend && python -m pytest tests/unit/ocr/test_lightonocr_client.py -v`
2. All tests should pass
3. Count tests: `grep -c "def test_" backend/tests/unit/ocr/test_lightonocr_client.py` should show 15+ tests
  </verify>
  <done>
- backend/tests/unit/ocr/__init__.py exists
- backend/tests/unit/ocr/test_lightonocr_client.py exists with 15+ comprehensive tests
- All tests pass using mocks (no actual GPU service calls)
  </done>
</task>

</tasks>

<verification>
1. `python -c "from src.ocr import LightOnOCRClient"` imports successfully
2. `cd backend && python -m pytest tests/unit/ocr/ -v` all tests pass
3. `grep "LOCR-06" backend/src/ocr/lightonocr_client.py` finds requirement reference
</verification>

<success_criteria>
- LightOnOCRClient implements async extract_text method (LOCR-06)
- Client uses OIDC authentication for Cloud Run service-to-service calls (LOCR-07)
- Client uses vLLM OpenAI-compatible chat completions API
- All unit tests pass with mocked HTTP and auth
- Error cases handled gracefully with LightOnOCRError
</success_criteria>

<output>
After completion, create `.planning/phases/13-lightonocr-gpu-service/13-03-SUMMARY.md`
</output>
