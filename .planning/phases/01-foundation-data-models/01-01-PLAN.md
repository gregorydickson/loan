---
phase: 01-foundation-data-models
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/pyproject.toml
  - backend/src/__init__.py
  - backend/src/main.py
  - backend/src/config.py
  - backend/src/models/__init__.py
  - backend/.env.example
  - backend/tests/__init__.py
  - backend/tests/conftest.py
  - docker-compose.yml
  - .gitignore
autonomous: true

must_haves:
  truths:
    - "Running `python -c \"import src\"` succeeds in backend directory after pip install -e ."
    - "Running `docker-compose up -d` starts PostgreSQL container with health check passing"
    - "Running `docker-compose up -d` starts Redis container with health check passing"
    - "Environment config loads from .env file via pydantic-settings"
  artifacts:
    - path: "backend/pyproject.toml"
      provides: "Python project configuration with all dependencies"
      contains: "[build-system]"
    - path: "backend/src/config.py"
      provides: "Type-safe settings from environment"
      contains: "class Settings"
    - path: "backend/src/main.py"
      provides: "FastAPI app entry point"
      contains: "FastAPI"
    - path: "docker-compose.yml"
      provides: "Local PostgreSQL and Redis services"
      contains: "healthcheck"
  key_links:
    - from: "backend/src/config.py"
      to: ".env"
      via: "pydantic-settings env_file"
      pattern: "env_file.*\\.env"
    - from: "backend/src/main.py"
      to: "backend/src/config.py"
      via: "settings import"
      pattern: "from.*config.*import.*settings"
---

<objective>
Create the Python backend project structure with all dependencies, configuration, and local development infrastructure.

Purpose: Establish the foundation that all backend work builds upon. A correctly configured pyproject.toml prevents dependency conflicts during the 3-day deadline. Docker Compose provides PostgreSQL and Redis for local development.

Output: Working Python package that imports successfully, FastAPI app skeleton, and Docker services for database/cache.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation-data-models/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create backend project structure with pyproject.toml</name>
  <files>
    backend/pyproject.toml
    backend/src/__init__.py
    backend/src/main.py
    backend/src/config.py
    backend/src/models/__init__.py
    backend/tests/__init__.py
    backend/tests/conftest.py
    backend/.env.example
  </files>
  <action>
Create the backend directory structure following FastAPI best practices from RESEARCH.md.

1. Create `backend/pyproject.toml` with:
   - [build-system] using setuptools>=75.0 (CRITICAL - enables pip install -e .)
   - [project] with name="loan-extraction-backend", version="0.1.0", requires-python=">=3.10"
   - All dependencies from RESEARCH.md including: fastapi>=0.128.0, uvicorn[standard]>=0.34.0, pydantic>=2.12.0, pydantic-settings>=2.7.0, sqlalchemy[asyncio]>=2.0.46, asyncpg>=0.31.0, alembic>=1.18.0, python-multipart>=0.0.18, httpx>=0.28.0, structlog>=25.5.0, docling>=2.70.0, google-genai>=1.60.0, google-cloud-storage>=2.18.0, tenacity>=9.0.0
   - [project.optional-dependencies] dev section with: pytest>=8.3.0, pytest-asyncio>=1.3.0, pytest-cov>=6.0.0, mypy>=1.14.0, ruff>=0.8.0
   - [tool.setuptools.packages.find] with where=["."], include=["src*"]
   - [tool.pytest.ini_options] with testpaths=["tests"], asyncio_mode="auto", asyncio_default_fixture_loop_scope="function"
   - [tool.mypy] with python_version="3.12", strict=true, plugins=["pydantic.mypy"]
   - [tool.pydantic-mypy] configuration
   - [tool.ruff] and [tool.ruff.lint] configuration

2. Create `backend/src/__init__.py` (empty, makes src a package)

3. Create `backend/src/models/__init__.py` (empty, placeholder for Phase 01-03)

4. Create `backend/src/config.py` with Settings class:
   - Use pydantic_settings BaseSettings with SettingsConfigDict
   - Include: database_url (PostgresDsn), redis_url (RedisDsn), api_host, api_port, debug, gemini_api_key
   - Use defaults matching docker-compose (postgres://postgres:postgres@localhost:5432/loan_extraction)
   - Create singleton settings = Settings() at module level

5. Create `backend/src/main.py` with:
   - FastAPI app with lifespan context manager (placeholder for DB connection)
   - /health endpoint returning {"status": "healthy"}
   - Import settings from config

6. Create `backend/tests/__init__.py` (empty)

7. Create `backend/tests/conftest.py` with:
   - pytest fixtures placeholder
   - Comment indicating async fixtures will be added

8. Create `backend/.env.example` with all environment variables documented

AVOID: Using deprecated datetime.utcnow() - use datetime.now(timezone.utc). Using Pydantic v1 patterns.
  </action>
  <verify>
cd backend && pip install -e ".[dev]" && python -c "import src; from src.config import settings; from src.main import app; print('Backend import OK')"
  </verify>
  <done>
Backend Python package installs successfully. `import src` works. Settings load from environment. FastAPI app exists with /health endpoint.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Docker Compose for local development</name>
  <files>
    docker-compose.yml
    .gitignore
  </files>
  <action>
Create Docker Compose configuration for PostgreSQL and Redis with health checks.

1. Create `docker-compose.yml` at project root with:
   - postgres service using postgres:16-alpine image
   - Environment: POSTGRES_USER=postgres, POSTGRES_PASSWORD=postgres, POSTGRES_DB=loan_extraction
   - Port mapping 5432:5432
   - Volume postgres_data:/var/lib/postgresql/data
   - Healthcheck using pg_isready -U postgres -d loan_extraction (interval: 5s, timeout: 5s, retries: 5, start_period: 10s)

   - redis service using redis:7-alpine image
   - Port mapping 6379:6379
   - Volume redis_data:/data
   - Healthcheck using redis-cli ping (interval: 5s, timeout: 3s, retries: 3)

   - volumes section declaring postgres_data and redis_data

2. Update or create `.gitignore` at project root to include:
   - Python: __pycache__/, *.py[cod], *.egg-info/, dist/, build/, .eggs/
   - Environment: .env, .env.local, *.env (but NOT .env.example)
   - IDE: .vscode/, .idea/
   - Testing: .coverage, htmlcov/, .pytest_cache/
   - mypy: .mypy_cache/
   - Node: node_modules/, .next/, out/
   - OS: .DS_Store
   - Logs: *.log

AVOID: Using `depends_on` without condition (causes race conditions). Missing healthcheck (services start before ready).
  </action>
  <verify>
docker-compose up -d && sleep 10 && docker-compose ps | grep -E "(healthy|running)" && docker-compose exec postgres pg_isready -U postgres && docker-compose exec redis redis-cli ping
  </verify>
  <done>
PostgreSQL container starts and passes healthcheck. Redis container starts and responds to ping. Both services accessible at localhost:5432 and localhost:6379.
  </done>
</task>

</tasks>

<verification>
Run the following to verify Phase 01-01 completion:

```bash
# 1. Backend package imports successfully
cd backend && pip install -e ".[dev]" && python -c "import src; print('OK')"

# 2. Docker services healthy
docker-compose up -d && sleep 10 && docker-compose ps

# 3. FastAPI app starts (verify no import errors)
cd backend && timeout 5 uvicorn src.main:app --host 0.0.0.0 --port 8000 || true
curl -s http://localhost:8000/health | grep healthy
```
</verification>

<success_criteria>
1. `pip install -e ".[dev]"` completes without errors in backend/
2. `python -c "import src"` succeeds
3. `docker-compose up -d` starts both postgres and redis
4. Both containers show "healthy" status in `docker-compose ps`
5. `curl localhost:8000/health` returns `{"status":"healthy"}` when uvicorn running
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation-data-models/01-01-SUMMARY.md`
</output>
