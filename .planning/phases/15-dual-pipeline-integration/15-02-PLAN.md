---
phase: 15-dual-pipeline-integration
plan: 02
type: execute
wave: 2
depends_on: ["15-01"]
files_modified:
  - backend/src/ingestion/cloud_tasks_client.py
  - backend/src/api/tasks.py
  - backend/src/ingestion/document_service.py
  - backend/src/api/dependencies.py
autonomous: true

must_haves:
  truths:
    - "Cloud Tasks payload includes method and ocr parameters"
    - "Task handler uses method and ocr parameters for extraction"
    - "DocumentService passes extraction parameters through pipeline"
    - "ExtractionRouter is called with correct method parameter"
    - "Document record updated with extraction_method after processing"
    - "Document record updated with ocr_processed after processing"
  artifacts:
    - path: "backend/src/ingestion/cloud_tasks_client.py"
      provides: "Enhanced Cloud Tasks payload with method/ocr"
      contains: "method.*extraction_method"
    - path: "backend/src/api/tasks.py"
      provides: "Task handler using extraction parameters"
      contains: "ProcessDocumentRequest.*method"
    - path: "backend/src/ingestion/document_service.py"
      provides: "DocumentService wired to ExtractionRouter"
      contains: "extraction_method"
  key_links:
    - from: "backend/src/ingestion/cloud_tasks_client.py"
      to: "backend/src/api/tasks.py"
      via: "JSON payload with method/ocr fields"
      pattern: '"method".*"ocr"'
    - from: "backend/src/api/tasks.py"
      to: "backend/src/extraction/extraction_router.py"
      via: "ExtractionRouter.extract() call"
      pattern: "extraction_router.*extract"
    - from: "backend/src/ingestion/document_service.py"
      to: "backend/src/storage/models.py"
      via: "Document.extraction_method update"
      pattern: "extraction_method"
---

<objective>
Wire Cloud Tasks and DocumentService to pass extraction parameters through the full processing pipeline.

Purpose: Complete the dual pipeline integration by ensuring method and OCR selections flow from API through Cloud Tasks to the extraction layer, with metadata recorded on documents.

Output: Fully functional dual pipeline selection via ?method and ?ocr parameters, working for both sync (local dev) and async (Cloud Tasks) processing modes.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-dual-pipeline-integration/15-RESEARCH.md
@.planning/phases/15-dual-pipeline-integration/15-01-SUMMARY.md

# Existing source files
@backend/src/ingestion/cloud_tasks_client.py
@backend/src/api/tasks.py
@backend/src/ingestion/document_service.py
@backend/src/api/dependencies.py
@backend/src/extraction/extraction_router.py
@backend/src/ocr/ocr_router.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enhance Cloud Tasks payload with method and ocr parameters</name>
  <files>
    backend/src/ingestion/cloud_tasks_client.py
    backend/src/api/tasks.py
  </files>
  <action>
1. Update CloudTasksClient.create_document_processing_task() in cloud_tasks_client.py:
   - Add extraction_method and ocr_mode parameters (with default values)
   - Include in JSON payload:
     ```python
     def create_document_processing_task(
         self,
         document_id: UUID,
         filename: str,
         extraction_method: str = "docling",
         ocr_mode: str = "auto",
     ) -> tasks_v2.Task:
         payload = json.dumps({
             "document_id": str(document_id),
             "filename": filename,
             "method": extraction_method,
             "ocr": ocr_mode,
         }).encode()
     ```

2. Update ProcessDocumentRequest in tasks.py:
   - Add method field with default "docling" (backward compatible)
   - Add ocr field with default "auto"
   ```python
   class ProcessDocumentRequest(BaseModel):
       document_id: UUID = Field(..., description="Document UUID to process")
       filename: str = Field(..., description="Original filename")
       method: str = Field(default="docling", description="Extraction method: docling|langextract|auto")
       ocr: str = Field(default="auto", description="OCR mode: auto|force|skip")
   ```

Note: Default values ensure backward compatibility with any tasks already in queue.
  </action>
  <verify>
    cd /Users/gregorydickson/stackpoint/loan/backend && python -c "
from src.ingestion.cloud_tasks_client import CloudTasksClient
from src.api.tasks import ProcessDocumentRequest
import inspect

# Check CloudTasksClient signature
sig = inspect.signature(CloudTasksClient.create_document_processing_task)
params = list(sig.parameters.keys())
assert 'extraction_method' in params, 'Missing extraction_method param'
assert 'ocr_mode' in params, 'Missing ocr_mode param'
print('CloudTasksClient OK')

# Check ProcessDocumentRequest fields
req = ProcessDocumentRequest(document_id='00000000-0000-0000-0000-000000000000', filename='test.pdf')
assert hasattr(req, 'method'), 'Missing method field'
assert hasattr(req, 'ocr'), 'Missing ocr field'
assert req.method == 'docling', 'Default method should be docling'
assert req.ocr == 'auto', 'Default ocr should be auto'
print('ProcessDocumentRequest OK')
"
  </verify>
  <done>
    CloudTasksClient includes method/ocr in payload. ProcessDocumentRequest parses method/ocr fields with backward-compatible defaults.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire DocumentService to use ExtractionRouter with parameters</name>
  <files>
    backend/src/ingestion/document_service.py
    backend/src/api/dependencies.py
  </files>
  <action>
1. Update DocumentService.__init__() to accept ExtractionRouter:
   ```python
   from src.extraction.extraction_router import ExtractionRouter

   def __init__(
       self,
       repository: DocumentRepository,
       gcs_client: GCSClient,
       docling_processor: DoclingProcessor,
       borrower_extractor: BorrowerExtractor,
       borrower_repository: BorrowerRepository,
       cloud_tasks_client: CloudTasksClient | None = None,
       extraction_router: ExtractionRouter | None = None,  # NEW
   ) -> None:
       ...
       self.extraction_router = extraction_router
   ```

2. Update DocumentService.upload() signature:
   ```python
   async def upload(
       self,
       filename: str,
       content: bytes,
       content_type: str | None = None,
       extraction_method: str = "docling",  # NEW
       ocr_mode: str = "auto",              # NEW
   ) -> Document:
   ```

3. In upload(), when creating document record, set extraction_method:
   ```python
   document = Document(
       id=document_id,
       filename=filename,
       file_hash=file_hash,
       file_type=file_type,
       file_size_bytes=len(content),
       status=DocumentStatus.PENDING,
       extraction_method=extraction_method,  # NEW
   )
   ```

4. In upload(), pass parameters to CloudTasksClient:
   ```python
   self.cloud_tasks_client.create_document_processing_task(
       document_id=document_id,
       filename=filename,
       extraction_method=extraction_method,
       ocr_mode=ocr_mode,
   )
   ```

5. In sync mode processing, use ExtractionRouter if available:
   ```python
   # After Docling processing, choose extractor based on method
   if self.extraction_router and extraction_method != "docling":
       extraction_result = self.extraction_router.extract(
           document=result,
           document_id=document_id,
           document_name=filename,
           method=extraction_method,  # Use selected method
       )
   else:
       # Original behavior - use direct BorrowerExtractor
       extraction_result = self.borrower_extractor.extract(
           document=result,
           document_id=document_id,
           document_name=filename,
       )
   ```

6. After processing completes (both sync and async), update document with:
   - extraction_method: Already set at creation
   - ocr_processed: Set based on whether OCR was used (can be determined from result metadata or set to None for now, refined in Phase 17)

7. Update dependencies.py to inject ExtractionRouter:
   - Create get_extraction_router() function that builds ExtractionRouter with LangExtractProcessor and BorrowerExtractor
   - Add ExtractionRouterDep type alias
   - Update get_document_service() to include extraction_router
  </action>
  <verify>
    cd /Users/gregorydickson/stackpoint/loan/backend && python -c "
from src.ingestion.document_service import DocumentService
import inspect

sig = inspect.signature(DocumentService.upload)
params = list(sig.parameters.keys())
print(f'upload params: {params}')
assert 'extraction_method' in params, 'Missing extraction_method'
assert 'ocr_mode' in params, 'Missing ocr_mode'
print('DocumentService.upload OK')
"
  </verify>
  <done>
    DocumentService accepts extraction_method and ocr_mode parameters, passes them to Cloud Tasks, and uses ExtractionRouter for non-docling methods.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update task handler to use extraction parameters</name>
  <files>
    backend/src/api/tasks.py
    backend/src/api/dependencies.py
  </files>
  <action>
1. Update process_document handler in tasks.py to use ExtractionRouter:
   - Add ExtractionRouterDep dependency injection
   - Use payload.method and payload.ocr for extraction decisions

2. Replace the current borrower_extractor.extract() call with ExtractionRouter:
   ```python
   @router.post("/process-document", ...)
   async def process_document(
       request: Request,
       payload: ProcessDocumentRequest,
       document_repo: DocumentRepoDep,
       docling_processor: DoclingProcessorDep,
       extraction_router: ExtractionRouterDep,  # CHANGED from borrower_extractor
       borrower_repo: BorrowerRepoDep,
       gcs_client: GCSClientDep,
   ) -> ProcessDocumentResponse:
       ...
       # Use ExtractionRouter with method from payload
       extraction_result = extraction_router.extract(
           document=result,
           document_id=payload.document_id,
           document_name=payload.filename,
           method=payload.method,  # Use selected method
       )
   ```

3. Update document metadata after extraction:
   ```python
   # After successful extraction, update document with metadata
   # extraction_method was already set at upload time
   # For ocr_processed, set to None for now (OCR tracking deferred to full OCRRouter integration)
   ```

4. Keep backward compatibility:
   - If payload.method not in request (old tasks in queue), default to "docling"
   - ProcessDocumentRequest already has default values, so this is automatic

5. Update the borrower persistence loop to handle both ExtractionResult and LangExtractResult:
   - Both produce .borrowers list with BorrowerRecord items
   - Existing persistence code should work unchanged
  </action>
  <verify>
    cd /Users/gregorydickson/stackpoint/loan/backend && python -c "
from src.api.tasks import process_document
import inspect

# Check signature includes extraction_router
sig = inspect.signature(process_document)
params = list(sig.parameters.keys())
print(f'process_document params: {params}')

# Verify ExtractionRouterDep is in dependencies
from src.api.dependencies import ExtractionRouterDep
print('ExtractionRouterDep imported OK')
"
  </verify>
  <done>
    Task handler uses ExtractionRouter with method parameter from payload. Both sync and async paths use the same extraction routing logic.
  </done>
</task>

</tasks>

<verification>
1. Cloud Tasks payload verification:
   ```bash
   cd /Users/gregorydickson/stackpoint/loan/backend
   python -c "
   import json
   from unittest.mock import MagicMock, patch
   from uuid import uuid4
   from src.ingestion.cloud_tasks_client import CloudTasksClient

   # Mock the Cloud Tasks client
   with patch('google.cloud.tasks_v2.CloudTasksClient'):
       client = CloudTasksClient('proj', 'loc', 'queue', 'http://url', 'sa@email')
       client.client = MagicMock()
       client.client.create_task = MagicMock(return_value=MagicMock(name='task-1'))

       # Create task with parameters
       client.create_document_processing_task(
           uuid4(), 'test.pdf',
           extraction_method='langextract',
           ocr_mode='force'
       )

       # Verify payload
       call_args = client.client.create_task.call_args
       task = call_args[0][0].task
       payload = json.loads(task.http_request.body)
       print(f'Payload: {payload}')
       assert payload['method'] == 'langextract'
       assert payload['ocr'] == 'force'
       print('Cloud Tasks payload OK')
   "
   ```

2. Full integration test (compile check):
   ```bash
   cd /Users/gregorydickson/stackpoint/loan/backend
   python -c "
   from src.api.documents import router as docs_router
   from src.api.tasks import router as tasks_router
   from src.api.dependencies import ExtractionRouterDep
   from src.ingestion.document_service import DocumentService
   print('All modules import OK')
   "
   ```

3. Type consistency check:
   ```bash
   cd /Users/gregorydickson/stackpoint/loan/backend
   python -m mypy src/api/documents.py src/api/tasks.py src/ingestion/document_service.py --ignore-missing-imports 2>/dev/null || echo "mypy check (informational)"
   ```
</verification>

<success_criteria>
- CloudTasksClient.create_document_processing_task() accepts extraction_method and ocr_mode
- Cloud Tasks payload includes method and ocr fields
- ProcessDocumentRequest has method and ocr fields with defaults
- DocumentService.upload() accepts extraction_method and ocr_mode parameters
- DocumentService passes parameters to Cloud Tasks in async mode
- DocumentService uses ExtractionRouter in sync mode
- Task handler uses ExtractionRouter with method from payload
- ExtractionRouterDep defined in dependencies.py
- Document.extraction_method populated at upload time
- Backward compatibility maintained (defaults for missing params)
</success_criteria>

<output>
After completion, create `.planning/phases/15-dual-pipeline-integration/15-02-SUMMARY.md`
</output>
