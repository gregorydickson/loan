---
phase: 15-dual-pipeline-integration
plan: 02
type: execute
wave: 2
depends_on: ["15-01"]
files_modified:
  - backend/src/ingestion/cloud_tasks_client.py
  - backend/src/api/tasks.py
  - backend/src/ingestion/document_service.py
  - backend/src/api/dependencies.py
autonomous: true

must_haves:
  truths:
    - "Cloud Tasks payload includes method and ocr parameters"
    - "Task handler uses method and ocr parameters for extraction"
    - "DocumentService passes extraction parameters through pipeline"
    - "OCRRouter is called before extraction when ocr parameter is not 'skip'"
    - "ExtractionRouter is called with correct method parameter"
    - "Document record updated with extraction_method after processing"
    - "Document record updated with ocr_processed based on OCRResult.ocr_method"
    - "LangExtract path populates character offsets (DUAL-08)"
  artifacts:
    - path: "backend/src/ingestion/cloud_tasks_client.py"
      provides: "Enhanced Cloud Tasks payload with method/ocr"
      contains: "method.*extraction_method"
    - path: "backend/src/api/tasks.py"
      provides: "Task handler using OCRRouter and ExtractionRouter"
      contains: "ProcessDocumentRequest.*method"
    - path: "backend/src/ingestion/document_service.py"
      provides: "DocumentService wired to OCRRouter and ExtractionRouter"
      contains: "ocr_router"
  key_links:
    - from: "backend/src/ingestion/cloud_tasks_client.py"
      to: "backend/src/api/tasks.py"
      via: "JSON payload with method/ocr fields"
      pattern: '"method".*"ocr"'
    - from: "backend/src/api/tasks.py"
      to: "backend/src/ocr/ocr_router.py"
      via: "OCRRouter.process() call before extraction"
      pattern: "ocr_router.*process"
    - from: "backend/src/api/tasks.py"
      to: "backend/src/extraction/extraction_router.py"
      via: "ExtractionRouter.extract() call"
      pattern: "extraction_router.*extract"
    - from: "backend/src/ingestion/document_service.py"
      to: "backend/src/storage/models.py"
      via: "Document.extraction_method and ocr_processed update"
      pattern: "ocr_processed"
---

<objective>
Wire Cloud Tasks and DocumentService to pass extraction parameters through the full processing pipeline, including OCRRouter integration.

Purpose: Complete the dual pipeline integration by ensuring method and OCR selections flow from API through Cloud Tasks to OCRRouter then extraction layer, with metadata recorded on documents.

Output: Fully functional dual pipeline selection via ?method and ?ocr parameters, working for both sync (local dev) and async (Cloud Tasks) processing modes. OCRRouter processes documents before extraction when needed.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-dual-pipeline-integration/15-RESEARCH.md
@.planning/phases/15-dual-pipeline-integration/15-01-SUMMARY.md

# Existing source files
@backend/src/ingestion/cloud_tasks_client.py
@backend/src/api/tasks.py
@backend/src/ingestion/document_service.py
@backend/src/api/dependencies.py
@backend/src/extraction/extraction_router.py
@backend/src/ocr/ocr_router.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Enhance Cloud Tasks payload with method and ocr parameters</name>
  <files>
    backend/src/ingestion/cloud_tasks_client.py
    backend/src/api/tasks.py
    backend/tests/api/test_tasks.py
  </files>
  <action>
1. Update CloudTasksClient.create_document_processing_task() in cloud_tasks_client.py:
   - Add extraction_method and ocr_mode parameters (with default values)
   - Include in JSON payload:
     ```python
     def create_document_processing_task(
         self,
         document_id: UUID,
         filename: str,
         extraction_method: str = "docling",
         ocr_mode: str = "auto",
     ) -> tasks_v2.Task:
         payload = json.dumps({
             "document_id": str(document_id),
             "filename": filename,
             "method": extraction_method,
             "ocr": ocr_mode,
         }).encode()
     ```

2. Update ProcessDocumentRequest in tasks.py:
   - Add method field with default "docling" (backward compatible)
   - Add ocr field with default "auto"
   ```python
   class ProcessDocumentRequest(BaseModel):
       document_id: UUID = Field(..., description="Document UUID to process")
       filename: str = Field(..., description="Original filename")
       method: str = Field(default="docling", description="Extraction method: docling|langextract|auto")
       ocr: str = Field(default="auto", description="OCR mode: auto|force|skip")
   ```

3. Add backward compatibility test for ProcessDocumentRequest:
   - Test that existing payloads (without method/ocr) parse correctly with defaults
   - Test that new payloads with method/ocr parse correctly
   ```python
   def test_process_document_request_backward_compat():
       # Old payload format (before Phase 15) should still work
       old_payload = {"document_id": "...", "filename": "test.pdf"}
       req = ProcessDocumentRequest(**old_payload)
       assert req.method == "docling"  # Default for backward compat
       assert req.ocr == "auto"        # Default
   ```

Note: Default values ensure backward compatibility with any tasks already in queue.
  </action>
  <verify>
    cd /Users/gregorydickson/stackpoint/loan/backend && python -c "
from src.ingestion.cloud_tasks_client import CloudTasksClient
from src.api.tasks import ProcessDocumentRequest
import inspect

# Check CloudTasksClient signature
sig = inspect.signature(CloudTasksClient.create_document_processing_task)
params = list(sig.parameters.keys())
assert 'extraction_method' in params, 'Missing extraction_method param'
assert 'ocr_mode' in params, 'Missing ocr_mode param'
print('CloudTasksClient OK')

# Check ProcessDocumentRequest fields
req = ProcessDocumentRequest(document_id='00000000-0000-0000-0000-000000000000', filename='test.pdf')
assert hasattr(req, 'method'), 'Missing method field'
assert hasattr(req, 'ocr'), 'Missing ocr field'
assert req.method == 'docling', 'Default method should be docling'
assert req.ocr == 'auto', 'Default ocr should be auto'
print('ProcessDocumentRequest OK')

# Backward compatibility test
old_payload = {'document_id': '00000000-0000-0000-0000-000000000001', 'filename': 'legacy.pdf'}
legacy_req = ProcessDocumentRequest(**old_payload)
assert legacy_req.method == 'docling', 'Backward compat failed: method'
assert legacy_req.ocr == 'auto', 'Backward compat failed: ocr'
print('Backward compatibility OK')
"
  </verify>
  <done>
    CloudTasksClient includes method/ocr in payload. ProcessDocumentRequest parses method/ocr fields with backward-compatible defaults. Backward compatibility tested for legacy payloads.
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire DocumentService and task handler to use OCRRouter and ExtractionRouter</name>
  <files>
    backend/src/ingestion/document_service.py
    backend/src/api/dependencies.py
    backend/src/api/tasks.py
  </files>
  <action>
1. Update DocumentService.__init__() to accept OCRRouter and ExtractionRouter:
   ```python
   from src.extraction.extraction_router import ExtractionRouter
   from src.ocr.ocr_router import OCRRouter

   def __init__(
       self,
       repository: DocumentRepository,
       gcs_client: GCSClient,
       docling_processor: DoclingProcessor,
       borrower_extractor: BorrowerExtractor,
       borrower_repository: BorrowerRepository,
       cloud_tasks_client: CloudTasksClient | None = None,
       ocr_router: OCRRouter | None = None,           # NEW - DUAL-04
       extraction_router: ExtractionRouter | None = None,
   ) -> None:
       ...
       self.ocr_router = ocr_router
       self.extraction_router = extraction_router
   ```

2. Update DocumentService.upload() signature:
   ```python
   async def upload(
       self,
       filename: str,
       content: bytes,
       content_type: str | None = None,
       extraction_method: str = "docling",
       ocr_mode: str = "auto",
   ) -> Document:
   ```

3. In upload(), when creating document record, set extraction_method:
   ```python
   document = Document(
       id=document_id,
       filename=filename,
       file_hash=file_hash,
       file_type=file_type,
       file_size_bytes=len(content),
       status=DocumentStatus.PENDING,
       extraction_method=extraction_method,
   )
   ```

4. In upload(), pass parameters to CloudTasksClient:
   ```python
   self.cloud_tasks_client.create_document_processing_task(
       document_id=document_id,
       filename=filename,
       extraction_method=extraction_method,
       ocr_mode=ocr_mode,
   )
   ```

5. In sync mode processing, wire OCRRouter BEFORE extraction (DUAL-04):
   ```python
   # Step 1: Run OCR routing if needed
   if self.ocr_router and ocr_mode != "skip":
       ocr_result = await self.ocr_router.process(
           pdf_bytes=content,
           filename=filename,
           mode=ocr_mode,  # "auto" or "force"
       )
       document_content = ocr_result.content
       # Track OCR status based on OCRResult
       ocr_processed = ocr_result.ocr_method != "none"
   else:
       # Skip OCR - use Docling directly
       document_content = self.docling_processor.process_bytes(content, filename)
       ocr_processed = False

   # Step 2: Run extraction with selected method
   if self.extraction_router and extraction_method != "docling":
       extraction_result = self.extraction_router.extract(
           document=document_content,
           document_id=document_id,
           document_name=filename,
           method=extraction_method,
       )
   else:
       # Original behavior - use direct BorrowerExtractor
       extraction_result = self.borrower_extractor.extract(
           document=document_content,
           document_id=document_id,
           document_name=filename,
       )
   ```

6. After processing, update document with ocr_processed:
   ```python
   # Update document with ocr_processed status
   document.ocr_processed = ocr_processed
   await self.repository.update(document)
   ```

7. Update dependencies.py to inject OCRRouter and ExtractionRouter:
   - Create get_ocr_router() function that builds OCRRouter with LightOnOCRClient and DoclingProcessor
   - Add OCRRouterDep type alias
   - Create get_extraction_router() function that builds ExtractionRouter with LangExtractProcessor and BorrowerExtractor
   - Add ExtractionRouterDep type alias
   - Update get_document_service() to include ocr_router and extraction_router

8. Update process_document handler in tasks.py to use OCRRouter before ExtractionRouter:
   ```python
   @router.post("/process-document", ...)
   async def process_document(
       request: Request,
       payload: ProcessDocumentRequest,
       document_repo: DocumentRepoDep,
       docling_processor: DoclingProcessorDep,
       ocr_router: OCRRouterDep,              # NEW - DUAL-04
       extraction_router: ExtractionRouterDep,
       borrower_repo: BorrowerRepoDep,
       gcs_client: GCSClientDep,
   ) -> ProcessDocumentResponse:
       ...
       # Step 1: OCR routing based on payload.ocr mode
       if payload.ocr != "skip":
           ocr_result = await ocr_router.process(
               pdf_bytes=file_bytes,
               filename=payload.filename,
               mode=payload.ocr,
           )
           document_content = ocr_result.content
           ocr_processed = ocr_result.ocr_method != "none"
       else:
           document_content = docling_processor.process_bytes(file_bytes, payload.filename)
           ocr_processed = False

       # Step 2: Extraction routing based on payload.method
       extraction_result = extraction_router.extract(
           document=document_content,
           document_id=payload.document_id,
           document_name=payload.filename,
           method=payload.method,
       )

       # Step 3: Update document with metadata
       document.ocr_processed = ocr_processed
       # extraction_method already set at upload time
   ```

Note: This wiring ensures DUAL-04 (OCRRouter determines OCR need) is satisfied. The ocr_processed field is set based on OCRResult.ocr_method != "none".
  </action>
  <verify>
    cd /Users/gregorydickson/stackpoint/loan/backend && python -c "
from src.ingestion.document_service import DocumentService
from src.api.dependencies import OCRRouterDep, ExtractionRouterDep
import inspect

sig = inspect.signature(DocumentService.upload)
params = list(sig.parameters.keys())
print(f'upload params: {params}')
assert 'extraction_method' in params, 'Missing extraction_method'
assert 'ocr_mode' in params, 'Missing ocr_mode'
print('DocumentService.upload OK')

# Verify DocumentService.__init__ accepts ocr_router
init_sig = inspect.signature(DocumentService.__init__)
init_params = list(init_sig.parameters.keys())
assert 'ocr_router' in init_params, 'Missing ocr_router in __init__'
assert 'extraction_router' in init_params, 'Missing extraction_router in __init__'
print('DocumentService.__init__ OK')

print('OCRRouterDep imported OK')
print('ExtractionRouterDep imported OK')
"
  </verify>
  <done>
    DocumentService accepts extraction_method and ocr_mode parameters. OCRRouter is called BEFORE extraction when ocr != "skip" (DUAL-04). Document.ocr_processed is set based on OCRResult.ocr_method. ExtractionRouter handles method selection.
  </done>
</task>

<task type="auto">
  <name>Task 3: Verify character offset handling and add integration test</name>
  <files>
    backend/tests/integration/test_dual_pipeline.py
  </files>
  <action>
1. Create integration test file test_dual_pipeline.py to verify DUAL-08 (character offsets):
   ```python
   """Integration tests for dual pipeline extraction.

   DUAL-08: LangExtract path populates character offsets, Docling path leaves null
   """
   import pytest
   from uuid import uuid4
   from src.extraction.extraction_router import ExtractionRouter
   from src.extraction.langextract_processor import LangExtractProcessor
   from src.extraction.extractor import BorrowerExtractor
   from src.ingestion.docling_processor import DocumentContent

   @pytest.fixture
   def extraction_router():
       """Create ExtractionRouter with real processors."""
       langextract = LangExtractProcessor()
       docling_extractor = BorrowerExtractor(...)  # Configure as needed
       return ExtractionRouter(langextract, docling_extractor)

   def test_langextract_populates_char_offsets(extraction_router, sample_document):
       """DUAL-08: LangExtract path populates character offsets."""
       result = extraction_router.extract(
           document=sample_document,
           document_id=uuid4(),
           document_name="test.pdf",
           method="langextract",
       )
       # LangExtractResult should have borrowers with source_reference.char_start/char_end
       for borrower in result.borrowers:
           if borrower.source_reference:
               # LangExtract SHOULD populate offsets
               assert borrower.source_reference.char_start is not None or \
                      borrower.source_reference.char_end is not None, \
                      "LangExtract should populate char offsets (DUAL-08)"

   def test_docling_leaves_char_offsets_null(extraction_router, sample_document):
       """DUAL-08: Docling path leaves character offsets null."""
       result = extraction_router.extract(
           document=sample_document,
           document_id=uuid4(),
           document_name="test.pdf",
           method="docling",
       )
       # ExtractionResult from Docling may have null offsets (that's OK)
       # This test documents expected behavior
       for borrower in result.borrowers:
           if borrower.source_reference:
               # Docling may not populate char offsets - that's expected
               pass  # No assertion - just documenting behavior
   ```

2. The key verification for DUAL-08:
   - LangExtractProcessor.extract() returns LangExtractResult
   - LangExtractResult.borrowers have SourceReference with char_start/char_end populated
   - Verify in the test that these are NOT None for LangExtract path

3. If LangExtractProcessor doesn't populate offsets, this test will fail, alerting us to fix it.

Note: This test verifies DUAL-08 requirement explicitly. The test may need adjustment based on actual LangExtractProcessor output format.
  </action>
  <verify>
    cd /Users/gregorydickson/stackpoint/loan/backend && python -c "
# Verify test file exists
import os
test_path = 'tests/integration/test_dual_pipeline.py'
if os.path.exists(test_path):
    print(f'{test_path} exists')
else:
    print(f'{test_path} will be created')

# Verify LangExtractResult has char offset fields
from src.extraction.langextract_processor import LangExtractResult
from src.extraction.extractor import SourceReference
import inspect
print('LangExtractResult imported OK')
print('SourceReference imported OK')
# Check SourceReference has char_start/char_end
sr_fields = [f for f in dir(SourceReference) if 'char' in f.lower()]
print(f'SourceReference char fields: {sr_fields}')
"
  </verify>
  <done>
    Integration test for DUAL-08 verifies LangExtract populates character offsets while Docling path behavior is documented. Test file created at tests/integration/test_dual_pipeline.py.
  </done>
</task>

</tasks>

<verification>
1. Cloud Tasks payload verification:
   ```bash
   cd /Users/gregorydickson/stackpoint/loan/backend
   python -c "
   import json
   from unittest.mock import MagicMock, patch
   from uuid import uuid4
   from src.ingestion.cloud_tasks_client import CloudTasksClient

   # Mock the Cloud Tasks client
   with patch('google.cloud.tasks_v2.CloudTasksClient'):
       client = CloudTasksClient('proj', 'loc', 'queue', 'http://url', 'sa@email')
       client.client = MagicMock()
       client.client.create_task = MagicMock(return_value=MagicMock(name='task-1'))

       # Create task with parameters
       client.create_document_processing_task(
           uuid4(), 'test.pdf',
           extraction_method='langextract',
           ocr_mode='force'
       )

       # Verify payload
       call_args = client.client.create_task.call_args
       task = call_args[0][0].task
       payload = json.loads(task.http_request.body)
       print(f'Payload: {payload}')
       assert payload['method'] == 'langextract'
       assert payload['ocr'] == 'force'
       print('Cloud Tasks payload OK')
   "
   ```

2. OCRRouter wiring verification (DUAL-04):
   ```bash
   cd /Users/gregorydickson/stackpoint/loan/backend
   python -c "
   from src.api.dependencies import OCRRouterDep, ExtractionRouterDep
   from src.ingestion.document_service import DocumentService
   import inspect

   # Verify OCRRouter is in DocumentService
   init_sig = inspect.signature(DocumentService.__init__)
   params = list(init_sig.parameters.keys())
   assert 'ocr_router' in params, 'OCRRouter not wired to DocumentService'
   print('OCRRouter wired to DocumentService OK (DUAL-04)')
   "
   ```

3. Full integration test (compile check):
   ```bash
   cd /Users/gregorydickson/stackpoint/loan/backend
   python -c "
   from src.api.documents import router as docs_router
   from src.api.tasks import router as tasks_router
   from src.api.dependencies import OCRRouterDep, ExtractionRouterDep
   from src.ingestion.document_service import DocumentService
   print('All modules import OK')
   "
   ```

4. DUAL-08 verification (character offsets):
   ```bash
   cd /Users/gregorydickson/stackpoint/loan/backend
   pytest tests/integration/test_dual_pipeline.py -v -k "char_offset" 2>/dev/null || echo "Tests will run after implementation"
   ```

5. Type consistency check:
   ```bash
   cd /Users/gregorydickson/stackpoint/loan/backend
   python -m mypy src/api/documents.py src/api/tasks.py src/ingestion/document_service.py --ignore-missing-imports 2>/dev/null || echo "mypy check (informational)"
   ```
</verification>

<success_criteria>
- CloudTasksClient.create_document_processing_task() accepts extraction_method and ocr_mode
- Cloud Tasks payload includes method and ocr fields
- ProcessDocumentRequest has method and ocr fields with defaults
- ProcessDocumentRequest backward compatibility verified with test
- DocumentService.upload() accepts extraction_method and ocr_mode parameters
- DocumentService passes parameters to Cloud Tasks in async mode
- DocumentService uses OCRRouter BEFORE extraction in sync mode (DUAL-04)
- Task handler uses OCRRouter before ExtractionRouter (DUAL-04)
- OCRRouterDep and ExtractionRouterDep defined in dependencies.py
- Document.extraction_method populated at upload time
- Document.ocr_processed set based on OCRResult.ocr_method != "none"
- LangExtract path populates character offsets (DUAL-08 verified by test)
- Backward compatibility maintained (defaults for missing params)
</success_criteria>

<output>
After completion, create `.planning/phases/15-dual-pipeline-integration/15-02-SUMMARY.md`
</output>
